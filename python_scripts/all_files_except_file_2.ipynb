{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cd48921-89a5-4d08-98c9-bceccbdafdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The goal of this notebut is to clean and catergoized the data that will be used\n",
    "# for  \"Best State/Country/City to Live/Move in United States\" independent project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c665df3e-ef4a-4b3b-9201-7d1e0a961744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58f13ab4-5b31-4d8c-8ba0-f37bc8a9160a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_to_the_imput_folder\n",
    "input_path = '/Users/emilsafarov/Library/CloudStorage/OneDrive-Personal/CF/A6/1_sourceing_open_data/US project/Data/Input data'\n",
    "\n",
    "output_path = '/Users/emilsafarov/Library/CloudStorage/OneDrive-Personal/CF/A6/1_sourceing_open_data/US project/Data/Output data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dcdb484-16a5-4e65-a077-c9f00c0886ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/emilsafarov/Library/CloudStorage/OneDrive-Personal/CF/A6/1_sourceing_open_data/US project/Data/Input data/file_2_speed of internet.csv', '/Users/emilsafarov/Library/CloudStorage/OneDrive-Personal/CF/A6/1_sourceing_open_data/US project/Data/Input data/file_3_cost-of-living-index-by-state-2025.csv', '/Users/emilsafarov/Library/CloudStorage/OneDrive-Personal/CF/A6/1_sourceing_open_data/US project/Data/Input data/file_1.xlsx', '/Users/emilsafarov/Library/CloudStorage/OneDrive-Personal/CF/A6/1_sourceing_open_data/US project/Data/Input data/School financing/elsec14t.csv', '/Users/emilsafarov/Library/CloudStorage/OneDrive-Personal/CF/A6/1_sourceing_open_data/US project/Data/Input data/School financing/elsec14.csv', '/Users/emilsafarov/Library/CloudStorage/OneDrive-Personal/CF/A6/1_sourceing_open_data/US project/Data/Input data/School financing/elsec14_sttables.csv', '/Users/emilsafarov/Library/CloudStorage/OneDrive-Personal/CF/A6/1_sourceing_open_data/US project/Data/Input data/Multidimenational/analytic_data2024.csv', '/Users/emilsafarov/Library/CloudStorage/OneDrive-Personal/CF/A6/1_sourceing_open_data/US project/Data/Input data/Multidimenational/analytic_data2021.csv', '/Users/emilsafarov/Library/CloudStorage/OneDrive-Personal/CF/A6/1_sourceing_open_data/US project/Data/Input data/Multidimenational/analytic_data2020.csv', '/Users/emilsafarov/Library/CloudStorage/OneDrive-Personal/CF/A6/1_sourceing_open_data/US project/Data/Input data/Multidimenational/analytic_data2022.csv', '/Users/emilsafarov/Library/CloudStorage/OneDrive-Personal/CF/A6/1_sourceing_open_data/US project/Data/Input data/Multidimenational/analytic_data2023.csv', '/Users/emilsafarov/Library/CloudStorage/OneDrive-Personal/CF/A6/1_sourceing_open_data/US project/Data/Input data/Rent/fmr_2023_clean.xlsx', '/Users/emilsafarov/Library/CloudStorage/OneDrive-Personal/CF/A6/1_sourceing_open_data/US project/Data/Input data/Rent/fmr_2021.xlsx', '/Users/emilsafarov/Library/CloudStorage/OneDrive-Personal/CF/A6/1_sourceing_open_data/US project/Data/Input data/Rent/fmr_2020.xlsx', '/Users/emilsafarov/Library/CloudStorage/OneDrive-Personal/CF/A6/1_sourceing_open_data/US project/Data/Input data/Rent/fmr_2022_clean.xlsx', '/Users/emilsafarov/Library/CloudStorage/OneDrive-Personal/CF/A6/1_sourceing_open_data/US project/Data/Input data/Rent/fmr_2024.xlsx', '/Users/emilsafarov/Library/CloudStorage/OneDrive-Personal/CF/A6/1_sourceing_open_data/US project/Data/Input data/Income/ACSDT5Y2023.B19013-Column-Metadata.csv', '/Users/emilsafarov/Library/CloudStorage/OneDrive-Personal/CF/A6/1_sourceing_open_data/US project/Data/Input data/Income/file_4_median_income.csv', '/Users/emilsafarov/Library/CloudStorage/OneDrive-Personal/CF/A6/1_sourceing_open_data/US project/Data/Input data/population/ACSST5Y2023.S0101-Column-Metadata.csv', '/Users/emilsafarov/Library/CloudStorage/OneDrive-Personal/CF/A6/1_sourceing_open_data/US project/Data/Input data/population/ACSST5Y2023.S0101-Data.csv', '/Users/emilsafarov/Library/CloudStorage/OneDrive-Personal/CF/A6/1_sourceing_open_data/US project/Data/Input data/population/ACSST1Y2023.S0101-Data.csv', '/Users/emilsafarov/Library/CloudStorage/OneDrive-Personal/CF/A6/1_sourceing_open_data/US project/Data/Input data/population/ACSST1Y2023.S0101-Column-Metadata.csv', '/Users/emilsafarov/Library/CloudStorage/OneDrive-Personal/CF/A6/1_sourceing_open_data/US project/Data/Input data/Diversity/file_6_diversityindex.csv', '/Users/emilsafarov/Library/CloudStorage/OneDrive-Personal/CF/A6/1_sourceing_open_data/US project/Data/Input data/Diversity/file_5_ACSDP5Y2023.DP05-Data.csv', '/Users/emilsafarov/Library/CloudStorage/OneDrive-Personal/CF/A6/1_sourceing_open_data/US project/Data/Input data/Diversity/ACSDP5Y2023.DP05-Column-Metadata.csv', '/Users/emilsafarov/Library/CloudStorage/OneDrive-Personal/CF/A6/1_sourceing_open_data/US project/Data/Input data/Taxes/2025 State Income Tax Rates and Brackets  Tax Foundation.csv', '/Users/emilsafarov/Library/CloudStorage/OneDrive-Personal/CF/A6/1_sourceing_open_data/US project/Data/Input data/Taxes/LOST_January_2025_-_2_12_update.xlsx']\n"
     ]
    }
   ],
   "source": [
    "# Recursively collect all .csv, .xls, and .xlsx files\n",
    "data_files = []\n",
    "\n",
    "for root, dirs, files in os.walk(input_path):\n",
    "    for file in files:\n",
    "        if file.endswith(('.csv', '.xls', '.xlsx')):\n",
    "            full_path = os.path.join(root, file)\n",
    "            data_files.append(full_path)\n",
    "\n",
    "# Show all collected file paths\n",
    "print(data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "382bf703-6941-4085-89b1-55fe3e9b60a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>County</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "      <th>2022</th>\n",
       "      <th>2023</th>\n",
       "      <th>2024</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>58909</td>\n",
       "      <td>59191</td>\n",
       "      <td>59736</td>\n",
       "      <td>60436</td>\n",
       "      <td>61464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Baldwin County</td>\n",
       "      <td>233244</td>\n",
       "      <td>239411</td>\n",
       "      <td>246577</td>\n",
       "      <td>254107</td>\n",
       "      <td>261608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Barbour County</td>\n",
       "      <td>24975</td>\n",
       "      <td>24517</td>\n",
       "      <td>24722</td>\n",
       "      <td>24644</td>\n",
       "      <td>24358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Bibb County</td>\n",
       "      <td>22176</td>\n",
       "      <td>22344</td>\n",
       "      <td>21983</td>\n",
       "      <td>21890</td>\n",
       "      <td>22258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Blount County</td>\n",
       "      <td>59110</td>\n",
       "      <td>59050</td>\n",
       "      <td>59491</td>\n",
       "      <td>59777</td>\n",
       "      <td>60163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     State          County    2020    2021    2022    2023    2024\n",
       "0  Alabama  Autauga County   58909   59191   59736   60436   61464\n",
       "1  Alabama  Baldwin County  233244  239411  246577  254107  261608\n",
       "2  Alabama  Barbour County   24975   24517   24722   24644   24358\n",
       "3  Alabama     Bibb County   22176   22344   21983   21890   22258\n",
       "4  Alabama   Blount County   59110   59050   59491   59777   60163"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Find the full path for 'file_1.xlsx'\n",
    "file_path = [f for f in data_files if f.endswith(\"file_1.xlsx\")][0]  # Gets the first match\n",
    "\n",
    "# Step 2: Load it into a DataFrame\n",
    "file_1 = pd.read_excel(file_path)\n",
    "\n",
    "# Step 3: Check the first few rows\n",
    "file_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "873b0ea9-2546-4ec7-a66b-60772f55cb3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>County</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "      <th>2022</th>\n",
       "      <th>2023</th>\n",
       "      <th>2024</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3139</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Sweetwater County</td>\n",
       "      <td>42196</td>\n",
       "      <td>41630</td>\n",
       "      <td>41322</td>\n",
       "      <td>41288</td>\n",
       "      <td>41273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3140</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Teton County</td>\n",
       "      <td>23384</td>\n",
       "      <td>23613</td>\n",
       "      <td>23341</td>\n",
       "      <td>23368</td>\n",
       "      <td>23272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3141</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Uinta County</td>\n",
       "      <td>20461</td>\n",
       "      <td>20690</td>\n",
       "      <td>20722</td>\n",
       "      <td>20724</td>\n",
       "      <td>20621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3142</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Washakie County</td>\n",
       "      <td>7663</td>\n",
       "      <td>7727</td>\n",
       "      <td>7728</td>\n",
       "      <td>7736</td>\n",
       "      <td>7662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3143</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Weston County</td>\n",
       "      <td>6817</td>\n",
       "      <td>6747</td>\n",
       "      <td>6872</td>\n",
       "      <td>6828</td>\n",
       "      <td>6866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        State             County   2020   2021   2022   2023   2024\n",
       "3139  Wyoming  Sweetwater County  42196  41630  41322  41288  41273\n",
       "3140  Wyoming       Teton County  23384  23613  23341  23368  23272\n",
       "3141  Wyoming       Uinta County  20461  20690  20722  20724  20621\n",
       "3142  Wyoming    Washakie County   7663   7727   7728   7736   7662\n",
       "3143  Wyoming      Weston County   6817   6747   6872   6828   6866"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Check the first few rows\n",
    "file_1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b47a55d-74e1-4c53-b45b-21db819009cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_1.duplicated().sum()  # How many duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "facab543-5d71-4f0a-bb98-b881a7f1192d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State     0\n",
       "County    0\n",
       "2020      0\n",
       "2021      0\n",
       "2022      0\n",
       "2023      0\n",
       "2024      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_1.isnull().sum() # How many nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d962afff-86ce-421f-b96e-8e598281ce78",
   "metadata": {},
   "source": [
    "Cost of living index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4858015-ee2f-4ba5-bbc3-3ff6b6293806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stateFlagCode</th>\n",
       "      <th>state</th>\n",
       "      <th>CostOfLivingIndex_CostOfLivingIndex_num_2024</th>\n",
       "      <th>CostOfLivingIndex_GroceriesCostsIndex_num_2024</th>\n",
       "      <th>CostOfLivingIndex_HousingCostsIndex_num_2024</th>\n",
       "      <th>CostOfLivingIndex_UtilitiesCostsIndex_num_2024</th>\n",
       "      <th>CostOfLivingIndex_TransportationCostsIndex_num_2024</th>\n",
       "      <th>CostOfLivingIndex_HealthCostsIndex_num_2024</th>\n",
       "      <th>CostOfLivingIndex_MiscCostsIndex_num_2024</th>\n",
       "      <th>CostOfLivingIndex_CostOfLivingIndex_num_2023</th>\n",
       "      <th>CostOfLivingIndex_GroceriesCostsIndex_num_2023</th>\n",
       "      <th>CostOfLivingIndex_HousingCostsIndex_num_2023</th>\n",
       "      <th>CostOfLivingIndex_UtilitiesCostsIndex_num_2023</th>\n",
       "      <th>CostOfLivingIndex_TransportationCostsIndex_num_2023</th>\n",
       "      <th>CostOfLivingIndex_HealthCostsIndex_num_2023</th>\n",
       "      <th>CostOfLivingIndex_MiscCostsIndex_num_2023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>186.9</td>\n",
       "      <td>130.4</td>\n",
       "      <td>310.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>133.3</td>\n",
       "      <td>121.1</td>\n",
       "      <td>130.5</td>\n",
       "      <td>179.0</td>\n",
       "      <td>125.6</td>\n",
       "      <td>309.7</td>\n",
       "      <td>141.1</td>\n",
       "      <td>140.3</td>\n",
       "      <td>118.4</td>\n",
       "      <td>123.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>145.9</td>\n",
       "      <td>104.4</td>\n",
       "      <td>218.8</td>\n",
       "      <td>150.0</td>\n",
       "      <td>109.5</td>\n",
       "      <td>125.7</td>\n",
       "      <td>115.3</td>\n",
       "      <td>148.4</td>\n",
       "      <td>105.0</td>\n",
       "      <td>219.5</td>\n",
       "      <td>126.1</td>\n",
       "      <td>127.5</td>\n",
       "      <td>112.6</td>\n",
       "      <td>125.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>California</td>\n",
       "      <td>144.8</td>\n",
       "      <td>111.7</td>\n",
       "      <td>208.7</td>\n",
       "      <td>139.8</td>\n",
       "      <td>136.7</td>\n",
       "      <td>107.7</td>\n",
       "      <td>115.3</td>\n",
       "      <td>134.5</td>\n",
       "      <td>112.3</td>\n",
       "      <td>186.5</td>\n",
       "      <td>124.8</td>\n",
       "      <td>124.1</td>\n",
       "      <td>106.4</td>\n",
       "      <td>110.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>141.9</td>\n",
       "      <td>105.8</td>\n",
       "      <td>222.4</td>\n",
       "      <td>102.6</td>\n",
       "      <td>107.7</td>\n",
       "      <td>117.4</td>\n",
       "      <td>113.3</td>\n",
       "      <td>148.7</td>\n",
       "      <td>106.9</td>\n",
       "      <td>241.8</td>\n",
       "      <td>110.2</td>\n",
       "      <td>107.9</td>\n",
       "      <td>104.7</td>\n",
       "      <td>117.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>123.8</td>\n",
       "      <td>127.1</td>\n",
       "      <td>118.0</td>\n",
       "      <td>152.8</td>\n",
       "      <td>114.3</td>\n",
       "      <td>150.0</td>\n",
       "      <td>118.9</td>\n",
       "      <td>124.4</td>\n",
       "      <td>127.4</td>\n",
       "      <td>118.1</td>\n",
       "      <td>148.1</td>\n",
       "      <td>121.9</td>\n",
       "      <td>149.8</td>\n",
       "      <td>118.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stateFlagCode                 state  \\\n",
       "0            NaN                Hawaii   \n",
       "1            NaN         Massachusetts   \n",
       "2            NaN            California   \n",
       "3            NaN  District of Columbia   \n",
       "4            NaN                Alaska   \n",
       "\n",
       "   CostOfLivingIndex_CostOfLivingIndex_num_2024  \\\n",
       "0                                         186.9   \n",
       "1                                         145.9   \n",
       "2                                         144.8   \n",
       "3                                         141.9   \n",
       "4                                         123.8   \n",
       "\n",
       "   CostOfLivingIndex_GroceriesCostsIndex_num_2024  \\\n",
       "0                                           130.4   \n",
       "1                                           104.4   \n",
       "2                                           111.7   \n",
       "3                                           105.8   \n",
       "4                                           127.1   \n",
       "\n",
       "   CostOfLivingIndex_HousingCostsIndex_num_2024  \\\n",
       "0                                         310.0   \n",
       "1                                         218.8   \n",
       "2                                         208.7   \n",
       "3                                         222.4   \n",
       "4                                         118.0   \n",
       "\n",
       "   CostOfLivingIndex_UtilitiesCostsIndex_num_2024  \\\n",
       "0                                           198.0   \n",
       "1                                           150.0   \n",
       "2                                           139.8   \n",
       "3                                           102.6   \n",
       "4                                           152.8   \n",
       "\n",
       "   CostOfLivingIndex_TransportationCostsIndex_num_2024  \\\n",
       "0                                              133.3     \n",
       "1                                              109.5     \n",
       "2                                              136.7     \n",
       "3                                              107.7     \n",
       "4                                              114.3     \n",
       "\n",
       "   CostOfLivingIndex_HealthCostsIndex_num_2024  \\\n",
       "0                                        121.1   \n",
       "1                                        125.7   \n",
       "2                                        107.7   \n",
       "3                                        117.4   \n",
       "4                                        150.0   \n",
       "\n",
       "   CostOfLivingIndex_MiscCostsIndex_num_2024  \\\n",
       "0                                      130.5   \n",
       "1                                      115.3   \n",
       "2                                      115.3   \n",
       "3                                      113.3   \n",
       "4                                      118.9   \n",
       "\n",
       "   CostOfLivingIndex_CostOfLivingIndex_num_2023  \\\n",
       "0                                         179.0   \n",
       "1                                         148.4   \n",
       "2                                         134.5   \n",
       "3                                         148.7   \n",
       "4                                         124.4   \n",
       "\n",
       "   CostOfLivingIndex_GroceriesCostsIndex_num_2023  \\\n",
       "0                                           125.6   \n",
       "1                                           105.0   \n",
       "2                                           112.3   \n",
       "3                                           106.9   \n",
       "4                                           127.4   \n",
       "\n",
       "   CostOfLivingIndex_HousingCostsIndex_num_2023  \\\n",
       "0                                         309.7   \n",
       "1                                         219.5   \n",
       "2                                         186.5   \n",
       "3                                         241.8   \n",
       "4                                         118.1   \n",
       "\n",
       "   CostOfLivingIndex_UtilitiesCostsIndex_num_2023  \\\n",
       "0                                           141.1   \n",
       "1                                           126.1   \n",
       "2                                           124.8   \n",
       "3                                           110.2   \n",
       "4                                           148.1   \n",
       "\n",
       "   CostOfLivingIndex_TransportationCostsIndex_num_2023  \\\n",
       "0                                              140.3     \n",
       "1                                              127.5     \n",
       "2                                              124.1     \n",
       "3                                              107.9     \n",
       "4                                              121.9     \n",
       "\n",
       "   CostOfLivingIndex_HealthCostsIndex_num_2023  \\\n",
       "0                                        118.4   \n",
       "1                                        112.6   \n",
       "2                                        106.4   \n",
       "3                                        104.7   \n",
       "4                                        149.8   \n",
       "\n",
       "   CostOfLivingIndex_MiscCostsIndex_num_2023  \n",
       "0                                      123.8  \n",
       "1                                      125.8  \n",
       "2                                      110.9  \n",
       "3                                      117.7  \n",
       "4                                      118.8  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading cost of living data frame \n",
    "\n",
    "# Step 1: Find the full path for 'file_1.xlsx'\n",
    "file_path = [f for f in data_files if f.endswith(\"file_3_cost-of-living-index-by-state-2025.csv\")][0]  # Gets the first match\n",
    "\n",
    "file_3 = pd.read_csv(file_path)\n",
    "\n",
    "# Step 3: Check the first few rows\n",
    "file_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c3a8948-a344-40ac-bcf8-387f813d9e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# droping stateFlagCode column\n",
    "file_3 = file_3.drop(\"stateFlagCode\",  axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14f7e40a-26c7-4dac-b409-d2e74392d1be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['state',\n",
       " 'CostOfLivingIndex_CostOfLivingIndex_num_2024',\n",
       " 'CostOfLivingIndex_GroceriesCostsIndex_num_2024',\n",
       " 'CostOfLivingIndex_HousingCostsIndex_num_2024',\n",
       " 'CostOfLivingIndex_UtilitiesCostsIndex_num_2024',\n",
       " 'CostOfLivingIndex_TransportationCostsIndex_num_2024',\n",
       " 'CostOfLivingIndex_HealthCostsIndex_num_2024',\n",
       " 'CostOfLivingIndex_MiscCostsIndex_num_2024',\n",
       " 'CostOfLivingIndex_CostOfLivingIndex_num_2023',\n",
       " 'CostOfLivingIndex_GroceriesCostsIndex_num_2023',\n",
       " 'CostOfLivingIndex_HousingCostsIndex_num_2023',\n",
       " 'CostOfLivingIndex_UtilitiesCostsIndex_num_2023',\n",
       " 'CostOfLivingIndex_TransportationCostsIndex_num_2023',\n",
       " 'CostOfLivingIndex_HealthCostsIndex_num_2023',\n",
       " 'CostOfLivingIndex_MiscCostsIndex_num_2023']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(file_3.columns) # listing all columns in order to compare and decide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb6ab4c-4776-4fec-9568-874bcba8e9ff",
   "metadata": {},
   "source": [
    "After comparision of data for 2023 and 2024, as well as data for 2024 by Statistica I've decided to continue with data of 2024\n",
    "\n",
    "file_3[['state', 'CostOfLivingIndex_CostOfLivingIndex_num_2024','CostOfLivingIndex_CostOfLivingIndex_num_2023']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21bc52c7-d3e3-499e-8f78-0f1856199a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# droping columns for 2023\n",
    "file_3 = file_3.drop(['CostOfLivingIndex_CostOfLivingIndex_num_2023',\n",
    " 'CostOfLivingIndex_GroceriesCostsIndex_num_2023',\n",
    " 'CostOfLivingIndex_HousingCostsIndex_num_2023',\n",
    " 'CostOfLivingIndex_UtilitiesCostsIndex_num_2023',\n",
    " 'CostOfLivingIndex_TransportationCostsIndex_num_2023',\n",
    " 'CostOfLivingIndex_HealthCostsIndex_num_2023',\n",
    " 'CostOfLivingIndex_MiscCostsIndex_num_2023'],  axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee787d40-c00f-4a04-8f78-a46ab46df8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86ebdf7f-a1f3-45e6-bb03-e3063ef6fc36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>COL_Total_2024</th>\n",
       "      <th>COL_Groceries_2024</th>\n",
       "      <th>COL_Housing_2024</th>\n",
       "      <th>COL_Utilities_2024</th>\n",
       "      <th>COL_Transport_2024</th>\n",
       "      <th>COL_Health_2024</th>\n",
       "      <th>COL_Misc_2024</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hawaii</td>\n",
       "      <td>186.9</td>\n",
       "      <td>130.4</td>\n",
       "      <td>310.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>133.3</td>\n",
       "      <td>121.1</td>\n",
       "      <td>130.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>145.9</td>\n",
       "      <td>104.4</td>\n",
       "      <td>218.8</td>\n",
       "      <td>150.0</td>\n",
       "      <td>109.5</td>\n",
       "      <td>125.7</td>\n",
       "      <td>115.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>California</td>\n",
       "      <td>144.8</td>\n",
       "      <td>111.7</td>\n",
       "      <td>208.7</td>\n",
       "      <td>139.8</td>\n",
       "      <td>136.7</td>\n",
       "      <td>107.7</td>\n",
       "      <td>115.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>141.9</td>\n",
       "      <td>105.8</td>\n",
       "      <td>222.4</td>\n",
       "      <td>102.6</td>\n",
       "      <td>107.7</td>\n",
       "      <td>117.4</td>\n",
       "      <td>113.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>123.8</td>\n",
       "      <td>127.1</td>\n",
       "      <td>118.0</td>\n",
       "      <td>152.8</td>\n",
       "      <td>114.3</td>\n",
       "      <td>150.0</td>\n",
       "      <td>118.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  State  COL_Total_2024  COL_Groceries_2024  COL_Housing_2024  \\\n",
       "0                Hawaii           186.9               130.4             310.0   \n",
       "1         Massachusetts           145.9               104.4             218.8   \n",
       "2            California           144.8               111.7             208.7   \n",
       "3  District of Columbia           141.9               105.8             222.4   \n",
       "4                Alaska           123.8               127.1             118.0   \n",
       "\n",
       "   COL_Utilities_2024  COL_Transport_2024  COL_Health_2024  COL_Misc_2024  \n",
       "0               198.0               133.3            121.1          130.5  \n",
       "1               150.0               109.5            125.7          115.3  \n",
       "2               139.8               136.7            107.7          115.3  \n",
       "3               102.6               107.7            117.4          113.3  \n",
       "4               152.8               114.3            150.0          118.9  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_3 = file_3.rename(columns={\n",
    "    'state': 'State',\n",
    "    'CostOfLivingIndex_CostOfLivingIndex_num_2024': 'COL_Total_2024',\n",
    "    'CostOfLivingIndex_GroceriesCostsIndex_num_2024': 'COL_Groceries_2024',\n",
    "    'CostOfLivingIndex_HousingCostsIndex_num_2024': 'COL_Housing_2024',\n",
    "    'CostOfLivingIndex_UtilitiesCostsIndex_num_2024': 'COL_Utilities_2024',\n",
    "    'CostOfLivingIndex_TransportationCostsIndex_num_2024': 'COL_Transport_2024',\n",
    "    'CostOfLivingIndex_HealthCostsIndex_num_2024': 'COL_Health_2024',\n",
    "    'CostOfLivingIndex_MiscCostsIndex_num_2024': 'COL_Misc_2024'\n",
    "})\n",
    "\n",
    "file_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3165e02-a8c2-43fe-a146-1c3bf57ecb72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>COL_Total_2024</th>\n",
       "      <th>COL_Groceries_2024</th>\n",
       "      <th>COL_Housing_2024</th>\n",
       "      <th>COL_Utilities_2024</th>\n",
       "      <th>COL_Transport_2024</th>\n",
       "      <th>COL_Health_2024</th>\n",
       "      <th>COL_Misc_2024</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>88.0</td>\n",
       "      <td>97.2</td>\n",
       "      <td>69.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>90.8</td>\n",
       "      <td>87.0</td>\n",
       "      <td>95.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Mississippi</td>\n",
       "      <td>87.9</td>\n",
       "      <td>96.3</td>\n",
       "      <td>73.9</td>\n",
       "      <td>88.9</td>\n",
       "      <td>89.8</td>\n",
       "      <td>99.3</td>\n",
       "      <td>93.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Kansas</td>\n",
       "      <td>87.0</td>\n",
       "      <td>94.8</td>\n",
       "      <td>72.4</td>\n",
       "      <td>98.7</td>\n",
       "      <td>90.1</td>\n",
       "      <td>94.5</td>\n",
       "      <td>90.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>85.7</td>\n",
       "      <td>95.4</td>\n",
       "      <td>68.6</td>\n",
       "      <td>95.4</td>\n",
       "      <td>90.7</td>\n",
       "      <td>96.6</td>\n",
       "      <td>90.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>84.1</td>\n",
       "      <td>99.0</td>\n",
       "      <td>59.9</td>\n",
       "      <td>96.6</td>\n",
       "      <td>93.1</td>\n",
       "      <td>97.7</td>\n",
       "      <td>90.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            State  COL_Total_2024  COL_Groceries_2024  COL_Housing_2024  \\\n",
       "46        Alabama            88.0                97.2              69.5   \n",
       "47    Mississippi            87.9                96.3              73.9   \n",
       "48         Kansas            87.0                94.8              72.4   \n",
       "49       Oklahoma            85.7                95.4              68.6   \n",
       "50  West Virginia            84.1                99.0              59.9   \n",
       "\n",
       "    COL_Utilities_2024  COL_Transport_2024  COL_Health_2024  COL_Misc_2024  \n",
       "46               100.0                90.8             87.0           95.6  \n",
       "47                88.9                89.8             99.3           93.3  \n",
       "48                98.7                90.1             94.5           90.8  \n",
       "49                95.4                90.7             96.6           90.4  \n",
       "50                96.6                93.1             97.7           90.2  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_3.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e240073-b322-4625-8dba-e44e11a11b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved successfully at: /Users/emilsafarov/Library/CloudStorage/OneDrive-Personal/CF/A6/1_sourceing_open_data/US project/Data/Output data\n"
     ]
    }
   ],
   "source": [
    "# saving the file \n",
    "\n",
    "file_3.to_csv(f\"{output_path}/file_3_cleaned_cost_of_living_2024.csv\", index=False)\n",
    "print(\"File saved successfully at:\", output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3616fad4-3d5d-415a-9652-2e5945cab952",
   "metadata": {},
   "source": [
    "Working median_income data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f08004eb-9593-486b-8cc6-902ee3b0185b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEO_ID</th>\n",
       "      <th>NAME</th>\n",
       "      <th>B19013_001E</th>\n",
       "      <th>B19013_001M</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Geography</td>\n",
       "      <td>Geographic Area Name</td>\n",
       "      <td>Estimate!!Median household income in the past ...</td>\n",
       "      <td>Margin of Error!!Median household income in th...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0500000US01001</td>\n",
       "      <td>Autauga County, Alabama</td>\n",
       "      <td>69841</td>\n",
       "      <td>5512</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0500000US01003</td>\n",
       "      <td>Baldwin County, Alabama</td>\n",
       "      <td>75019</td>\n",
       "      <td>2751</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0500000US01005</td>\n",
       "      <td>Barbour County, Alabama</td>\n",
       "      <td>44290</td>\n",
       "      <td>2762</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0500000US01007</td>\n",
       "      <td>Bibb County, Alabama</td>\n",
       "      <td>51215</td>\n",
       "      <td>6678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           GEO_ID                     NAME  \\\n",
       "0       Geography     Geographic Area Name   \n",
       "1  0500000US01001  Autauga County, Alabama   \n",
       "2  0500000US01003  Baldwin County, Alabama   \n",
       "3  0500000US01005  Barbour County, Alabama   \n",
       "4  0500000US01007     Bibb County, Alabama   \n",
       "\n",
       "                                         B19013_001E  \\\n",
       "0  Estimate!!Median household income in the past ...   \n",
       "1                                              69841   \n",
       "2                                              75019   \n",
       "3                                              44290   \n",
       "4                                              51215   \n",
       "\n",
       "                                         B19013_001M  Unnamed: 4  \n",
       "0  Margin of Error!!Median household income in th...         NaN  \n",
       "1                                               5512         NaN  \n",
       "2                                               2751         NaN  \n",
       "3                                               2762         NaN  \n",
       "4                                               6678         NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading median income data frame \n",
    "\n",
    "# Find the full path for file path and get right data\n",
    "file_path = [f for f in data_files if f.endswith(\"file_4_median_income.csv\")][0]  # Gets the first match\n",
    "\n",
    "file_4 = pd.read_csv(file_path)\n",
    "\n",
    "# Step 3: Check the first few rows\n",
    "file_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ebc8fcff-eb1d-4bca-9c3e-286ee961d843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GEO_ID', 'NAME', 'B19013_001E', 'B19013_001M', 'Unnamed: 4'], dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_4.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15d7d76d-6094-4937-9d0b-03d0cbb504d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "file_4 = file_4.drop(['GEO_ID', 'Unnamed: 4'], axis = 1)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2505fe7-6380-47a1-a8ec-c6e21412603b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_4 = file_4.drop(0, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7e0f10b-d153-499d-85b4-7056cd8e9186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>B19013_001E</th>\n",
       "      <th>B19013_001M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Autauga County, Alabama</td>\n",
       "      <td>69841</td>\n",
       "      <td>5512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Baldwin County, Alabama</td>\n",
       "      <td>75019</td>\n",
       "      <td>2751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Barbour County, Alabama</td>\n",
       "      <td>44290</td>\n",
       "      <td>2762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bibb County, Alabama</td>\n",
       "      <td>51215</td>\n",
       "      <td>6678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Blount County, Alabama</td>\n",
       "      <td>61096</td>\n",
       "      <td>3328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      NAME B19013_001E B19013_001M\n",
       "1  Autauga County, Alabama       69841        5512\n",
       "2  Baldwin County, Alabama       75019        2751\n",
       "3  Barbour County, Alabama       44290        2762\n",
       "4     Bibb County, Alabama       51215        6678\n",
       "5   Blount County, Alabama       61096        3328"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c832eaa2-d2bd-4ca7-b4dc-f35e8f728707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Spliting Name column\n",
    "\n",
    "file_4[['County', 'State']] = file_4['NAME'].str.split(',', expand = True)\n",
    "# Drop the original 'NAME' column\n",
    "file_4 = file_4.drop('NAME', axis=1)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a80499f8-12be-456b-8718-3ac7e4494ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_4 = file_4.rename(columns={\n",
    "    'B19013_001E': 'Median_income',\n",
    "    'B19013_001M': 'Error_margin'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f2bcc7fd-f7ce-4d3a-8220-ac225c3eccfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Median_income</th>\n",
       "      <th>Error_margin</th>\n",
       "      <th>County</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69841</td>\n",
       "      <td>5512</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75019</td>\n",
       "      <td>2751</td>\n",
       "      <td>Baldwin County</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44290</td>\n",
       "      <td>2762</td>\n",
       "      <td>Barbour County</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51215</td>\n",
       "      <td>6678</td>\n",
       "      <td>Bibb County</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>61096</td>\n",
       "      <td>3328</td>\n",
       "      <td>Blount County</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Median_income Error_margin          County     State\n",
       "1         69841         5512  Autauga County   Alabama\n",
       "2         75019         2751  Baldwin County   Alabama\n",
       "3         44290         2762  Barbour County   Alabama\n",
       "4         51215         6678     Bibb County   Alabama\n",
       "5         61096         3328   Blount County   Alabama"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "afbcea9e-3ce1-49bb-9573-223f3a294043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "file_4 = file_4[['State', 'County', 'Median_income', 'Error_margin']]\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7e8b069d-f7a9-4966-8c1b-bc1a43d8a725",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tt/mzspvn2d7hb3qsps4c4lqh0c0000gn/T/ipykernel_19118/3869337593.py:6: DtypeWarning: Columns (2,4,6,8,10,12,13,14,15,16,18,20,22,24,26,27,28,29,30,32,33,34,35,36,37,38,40,41,42,44,45,46,47,48,50,52,54,56,58,60,62,66,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,138,139,140,141,142,143,144,145,146,147,148,149,150,152,154,155,156,157,158,159,160,161,162,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,192,194,198,200,201,202,203,204,206,208,210,212,214,215,216,217,218,220,221,222,223,226,228,229,230,232,233,234,235,236,238,240,242,246,248,250,254,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,326,327,328,329,330,331,332,333,334,335,336,337,338,340,342,343,344,345,346,347,348,349,350,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,372,374,375,376,377) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  file_5 = pd.read_csv(file_path)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEO_ID</th>\n",
       "      <th>NAME</th>\n",
       "      <th>DP05_0001E</th>\n",
       "      <th>DP05_0001M</th>\n",
       "      <th>DP05_0002E</th>\n",
       "      <th>DP05_0002M</th>\n",
       "      <th>DP05_0003E</th>\n",
       "      <th>DP05_0003M</th>\n",
       "      <th>DP05_0004E</th>\n",
       "      <th>DP05_0004M</th>\n",
       "      <th>...</th>\n",
       "      <th>DP05_0090PM</th>\n",
       "      <th>DP05_0091PE</th>\n",
       "      <th>DP05_0091PM</th>\n",
       "      <th>DP05_0092PE</th>\n",
       "      <th>DP05_0092PM</th>\n",
       "      <th>DP05_0093PE</th>\n",
       "      <th>DP05_0093PM</th>\n",
       "      <th>DP05_0094PE</th>\n",
       "      <th>DP05_0094PM</th>\n",
       "      <th>Unnamed: 378</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Geography</td>\n",
       "      <td>Geographic Area Name</td>\n",
       "      <td>Estimate!!SEX AND AGE!!Total population</td>\n",
       "      <td>Margin of Error!!SEX AND AGE!!Total population</td>\n",
       "      <td>Estimate!!SEX AND AGE!!Total population!!Male</td>\n",
       "      <td>Margin of Error!!SEX AND AGE!!Total population...</td>\n",
       "      <td>Estimate!!SEX AND AGE!!Total population!!Female</td>\n",
       "      <td>Margin of Error!!SEX AND AGE!!Total population...</td>\n",
       "      <td>Estimate!!SEX AND AGE!!Total population!!Sex r...</td>\n",
       "      <td>Margin of Error!!SEX AND AGE!!Total population...</td>\n",
       "      <td>...</td>\n",
       "      <td>Percent Margin of Error!!HISPANIC OR LATINO AN...</td>\n",
       "      <td>Percent!!Total housing units</td>\n",
       "      <td>Percent Margin of Error!!Total housing units</td>\n",
       "      <td>Percent!!CITIZEN, VOTING AGE POPULATION!!Citiz...</td>\n",
       "      <td>Percent Margin of Error!!CITIZEN, VOTING AGE P...</td>\n",
       "      <td>Percent!!CITIZEN, VOTING AGE POPULATION!!Citiz...</td>\n",
       "      <td>Percent Margin of Error!!CITIZEN, VOTING AGE P...</td>\n",
       "      <td>Percent!!CITIZEN, VOTING AGE POPULATION!!Citiz...</td>\n",
       "      <td>Percent Margin of Error!!CITIZEN, VOTING AGE P...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0500000US01001</td>\n",
       "      <td>Autauga County, Alabama</td>\n",
       "      <td>59285</td>\n",
       "      <td>*****</td>\n",
       "      <td>28669</td>\n",
       "      <td>263</td>\n",
       "      <td>30616</td>\n",
       "      <td>263</td>\n",
       "      <td>93.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>(X)</td>\n",
       "      <td>(X)</td>\n",
       "      <td>44761</td>\n",
       "      <td>(X)</td>\n",
       "      <td>47.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>52.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0500000US01003</td>\n",
       "      <td>Baldwin County, Alabama</td>\n",
       "      <td>239945</td>\n",
       "      <td>*****</td>\n",
       "      <td>117316</td>\n",
       "      <td>153</td>\n",
       "      <td>122629</td>\n",
       "      <td>153</td>\n",
       "      <td>95.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>(X)</td>\n",
       "      <td>(X)</td>\n",
       "      <td>184665</td>\n",
       "      <td>(X)</td>\n",
       "      <td>48.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>51.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0500000US01005</td>\n",
       "      <td>Barbour County, Alabama</td>\n",
       "      <td>24757</td>\n",
       "      <td>*****</td>\n",
       "      <td>12906</td>\n",
       "      <td>119</td>\n",
       "      <td>11851</td>\n",
       "      <td>119</td>\n",
       "      <td>108.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>(X)</td>\n",
       "      <td>(X)</td>\n",
       "      <td>19201</td>\n",
       "      <td>(X)</td>\n",
       "      <td>53.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>46.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0500000US01007</td>\n",
       "      <td>Bibb County, Alabama</td>\n",
       "      <td>22152</td>\n",
       "      <td>*****</td>\n",
       "      <td>11824</td>\n",
       "      <td>147</td>\n",
       "      <td>10328</td>\n",
       "      <td>147</td>\n",
       "      <td>114.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>(X)</td>\n",
       "      <td>(X)</td>\n",
       "      <td>17469</td>\n",
       "      <td>(X)</td>\n",
       "      <td>53.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>46.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  379 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           GEO_ID                     NAME  \\\n",
       "0       Geography     Geographic Area Name   \n",
       "1  0500000US01001  Autauga County, Alabama   \n",
       "2  0500000US01003  Baldwin County, Alabama   \n",
       "3  0500000US01005  Barbour County, Alabama   \n",
       "4  0500000US01007     Bibb County, Alabama   \n",
       "\n",
       "                                DP05_0001E  \\\n",
       "0  Estimate!!SEX AND AGE!!Total population   \n",
       "1                                    59285   \n",
       "2                                   239945   \n",
       "3                                    24757   \n",
       "4                                    22152   \n",
       "\n",
       "                                       DP05_0001M  \\\n",
       "0  Margin of Error!!SEX AND AGE!!Total population   \n",
       "1                                           *****   \n",
       "2                                           *****   \n",
       "3                                           *****   \n",
       "4                                           *****   \n",
       "\n",
       "                                      DP05_0002E  \\\n",
       "0  Estimate!!SEX AND AGE!!Total population!!Male   \n",
       "1                                          28669   \n",
       "2                                         117316   \n",
       "3                                          12906   \n",
       "4                                          11824   \n",
       "\n",
       "                                          DP05_0002M  \\\n",
       "0  Margin of Error!!SEX AND AGE!!Total population...   \n",
       "1                                                263   \n",
       "2                                                153   \n",
       "3                                                119   \n",
       "4                                                147   \n",
       "\n",
       "                                        DP05_0003E  \\\n",
       "0  Estimate!!SEX AND AGE!!Total population!!Female   \n",
       "1                                            30616   \n",
       "2                                           122629   \n",
       "3                                            11851   \n",
       "4                                            10328   \n",
       "\n",
       "                                          DP05_0003M  \\\n",
       "0  Margin of Error!!SEX AND AGE!!Total population...   \n",
       "1                                                263   \n",
       "2                                                153   \n",
       "3                                                119   \n",
       "4                                                147   \n",
       "\n",
       "                                          DP05_0004E  \\\n",
       "0  Estimate!!SEX AND AGE!!Total population!!Sex r...   \n",
       "1                                               93.6   \n",
       "2                                               95.7   \n",
       "3                                              108.9   \n",
       "4                                              114.5   \n",
       "\n",
       "                                          DP05_0004M  ...  \\\n",
       "0  Margin of Error!!SEX AND AGE!!Total population...  ...   \n",
       "1                                                1.7  ...   \n",
       "2                                                0.2  ...   \n",
       "3                                                2.1  ...   \n",
       "4                                                3.0  ...   \n",
       "\n",
       "                                         DP05_0090PM  \\\n",
       "0  Percent Margin of Error!!HISPANIC OR LATINO AN...   \n",
       "1                                                0.7   \n",
       "2                                                0.3   \n",
       "3                                                0.4   \n",
       "4                                                0.9   \n",
       "\n",
       "                    DP05_0091PE                                   DP05_0091PM  \\\n",
       "0  Percent!!Total housing units  Percent Margin of Error!!Total housing units   \n",
       "1                           (X)                                           (X)   \n",
       "2                           (X)                                           (X)   \n",
       "3                           (X)                                           (X)   \n",
       "4                           (X)                                           (X)   \n",
       "\n",
       "                                         DP05_0092PE  \\\n",
       "0  Percent!!CITIZEN, VOTING AGE POPULATION!!Citiz...   \n",
       "1                                              44761   \n",
       "2                                             184665   \n",
       "3                                              19201   \n",
       "4                                              17469   \n",
       "\n",
       "                                         DP05_0092PM  \\\n",
       "0  Percent Margin of Error!!CITIZEN, VOTING AGE P...   \n",
       "1                                                (X)   \n",
       "2                                                (X)   \n",
       "3                                                (X)   \n",
       "4                                                (X)   \n",
       "\n",
       "                                         DP05_0093PE  \\\n",
       "0  Percent!!CITIZEN, VOTING AGE POPULATION!!Citiz...   \n",
       "1                                               47.8   \n",
       "2                                               48.1   \n",
       "3                                               53.3   \n",
       "4                                               53.5   \n",
       "\n",
       "                                         DP05_0093PM  \\\n",
       "0  Percent Margin of Error!!CITIZEN, VOTING AGE P...   \n",
       "1                                                0.4   \n",
       "2                                                0.1   \n",
       "3                                                0.3   \n",
       "4                                                0.6   \n",
       "\n",
       "                                         DP05_0094PE  \\\n",
       "0  Percent!!CITIZEN, VOTING AGE POPULATION!!Citiz...   \n",
       "1                                               52.2   \n",
       "2                                               51.9   \n",
       "3                                               46.7   \n",
       "4                                               46.5   \n",
       "\n",
       "                                         DP05_0094PM Unnamed: 378  \n",
       "0  Percent Margin of Error!!CITIZEN, VOTING AGE P...          NaN  \n",
       "1                                                0.4          NaN  \n",
       "2                                                0.1          NaN  \n",
       "3                                                0.3          NaN  \n",
       "4                                                0.6          NaN  \n",
       "\n",
       "[5 rows x 379 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the dataset for diversity and more\n",
    "\n",
    "# Find the full path for 'file_1.xlsx'\n",
    "file_path = [f for f in data_files if f.endswith(\"file_5_ACSDP5Y2023.DP05-Data.csv\")][0]  # Gets the first match\n",
    "\n",
    "file_5 = pd.read_csv(file_path)\n",
    "\n",
    "# Step 3: Check the first few rows\n",
    "file_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ecbc8e45-a2e8-4f23-aedf-53729c39733b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GEO_ID',\n",
       " 'NAME',\n",
       " 'DP05_0001E',\n",
       " 'DP05_0001M',\n",
       " 'DP05_0002E',\n",
       " 'DP05_0002M',\n",
       " 'DP05_0003E',\n",
       " 'DP05_0003M',\n",
       " 'DP05_0004E',\n",
       " 'DP05_0004M',\n",
       " 'DP05_0005E',\n",
       " 'DP05_0005M',\n",
       " 'DP05_0006E',\n",
       " 'DP05_0006M',\n",
       " 'DP05_0007E',\n",
       " 'DP05_0007M',\n",
       " 'DP05_0008E',\n",
       " 'DP05_0008M',\n",
       " 'DP05_0009E',\n",
       " 'DP05_0009M',\n",
       " 'DP05_0010E',\n",
       " 'DP05_0010M',\n",
       " 'DP05_0011E',\n",
       " 'DP05_0011M',\n",
       " 'DP05_0012E',\n",
       " 'DP05_0012M',\n",
       " 'DP05_0013E',\n",
       " 'DP05_0013M',\n",
       " 'DP05_0014E',\n",
       " 'DP05_0014M',\n",
       " 'DP05_0015E',\n",
       " 'DP05_0015M',\n",
       " 'DP05_0016E',\n",
       " 'DP05_0016M',\n",
       " 'DP05_0017E',\n",
       " 'DP05_0017M',\n",
       " 'DP05_0018E',\n",
       " 'DP05_0018M',\n",
       " 'DP05_0019E',\n",
       " 'DP05_0019M',\n",
       " 'DP05_0020E',\n",
       " 'DP05_0020M',\n",
       " 'DP05_0021E',\n",
       " 'DP05_0021M',\n",
       " 'DP05_0022E',\n",
       " 'DP05_0022M',\n",
       " 'DP05_0023E',\n",
       " 'DP05_0023M',\n",
       " 'DP05_0024E',\n",
       " 'DP05_0024M',\n",
       " 'DP05_0025E',\n",
       " 'DP05_0025M',\n",
       " 'DP05_0026E',\n",
       " 'DP05_0026M',\n",
       " 'DP05_0027E',\n",
       " 'DP05_0027M',\n",
       " 'DP05_0028E',\n",
       " 'DP05_0028M',\n",
       " 'DP05_0029E',\n",
       " 'DP05_0029M',\n",
       " 'DP05_0030E',\n",
       " 'DP05_0030M',\n",
       " 'DP05_0031E',\n",
       " 'DP05_0031M',\n",
       " 'DP05_0032E',\n",
       " 'DP05_0032M',\n",
       " 'DP05_0033E',\n",
       " 'DP05_0033M',\n",
       " 'DP05_0034E',\n",
       " 'DP05_0034M',\n",
       " 'DP05_0035E',\n",
       " 'DP05_0035M',\n",
       " 'DP05_0036E',\n",
       " 'DP05_0036M',\n",
       " 'DP05_0037E',\n",
       " 'DP05_0037M',\n",
       " 'DP05_0038E',\n",
       " 'DP05_0038M',\n",
       " 'DP05_0039E',\n",
       " 'DP05_0039M',\n",
       " 'DP05_0040E',\n",
       " 'DP05_0040M',\n",
       " 'DP05_0041E',\n",
       " 'DP05_0041M',\n",
       " 'DP05_0042E',\n",
       " 'DP05_0042M',\n",
       " 'DP05_0043E',\n",
       " 'DP05_0043M',\n",
       " 'DP05_0044E',\n",
       " 'DP05_0044M',\n",
       " 'DP05_0045E',\n",
       " 'DP05_0045M',\n",
       " 'DP05_0046E',\n",
       " 'DP05_0046M',\n",
       " 'DP05_0047E',\n",
       " 'DP05_0047M',\n",
       " 'DP05_0048E',\n",
       " 'DP05_0048M',\n",
       " 'DP05_0049E',\n",
       " 'DP05_0049M',\n",
       " 'DP05_0050E',\n",
       " 'DP05_0050M',\n",
       " 'DP05_0051E',\n",
       " 'DP05_0051M',\n",
       " 'DP05_0052E',\n",
       " 'DP05_0052M',\n",
       " 'DP05_0053E',\n",
       " 'DP05_0053M',\n",
       " 'DP05_0054E',\n",
       " 'DP05_0054M',\n",
       " 'DP05_0055E',\n",
       " 'DP05_0055M',\n",
       " 'DP05_0056E',\n",
       " 'DP05_0056M',\n",
       " 'DP05_0057E',\n",
       " 'DP05_0057M',\n",
       " 'DP05_0058E',\n",
       " 'DP05_0058M',\n",
       " 'DP05_0059E',\n",
       " 'DP05_0059M',\n",
       " 'DP05_0060E',\n",
       " 'DP05_0060M',\n",
       " 'DP05_0061E',\n",
       " 'DP05_0061M',\n",
       " 'DP05_0062E',\n",
       " 'DP05_0062M',\n",
       " 'DP05_0063E',\n",
       " 'DP05_0063M',\n",
       " 'DP05_0064E',\n",
       " 'DP05_0064M',\n",
       " 'DP05_0065E',\n",
       " 'DP05_0065M',\n",
       " 'DP05_0066E',\n",
       " 'DP05_0066M',\n",
       " 'DP05_0067E',\n",
       " 'DP05_0067M',\n",
       " 'DP05_0068E',\n",
       " 'DP05_0068M',\n",
       " 'DP05_0069E',\n",
       " 'DP05_0069M',\n",
       " 'DP05_0070E',\n",
       " 'DP05_0070M',\n",
       " 'DP05_0071E',\n",
       " 'DP05_0071M',\n",
       " 'DP05_0072E',\n",
       " 'DP05_0072M',\n",
       " 'DP05_0073E',\n",
       " 'DP05_0073M',\n",
       " 'DP05_0074E',\n",
       " 'DP05_0074M',\n",
       " 'DP05_0075E',\n",
       " 'DP05_0075M',\n",
       " 'DP05_0076E',\n",
       " 'DP05_0076M',\n",
       " 'DP05_0077E',\n",
       " 'DP05_0077M',\n",
       " 'DP05_0078E',\n",
       " 'DP05_0078M',\n",
       " 'DP05_0079E',\n",
       " 'DP05_0079M',\n",
       " 'DP05_0080E',\n",
       " 'DP05_0080M',\n",
       " 'DP05_0081E',\n",
       " 'DP05_0081M',\n",
       " 'DP05_0082E',\n",
       " 'DP05_0082M',\n",
       " 'DP05_0083E',\n",
       " 'DP05_0083M',\n",
       " 'DP05_0084E',\n",
       " 'DP05_0084M',\n",
       " 'DP05_0085E',\n",
       " 'DP05_0085M',\n",
       " 'DP05_0086E',\n",
       " 'DP05_0086M',\n",
       " 'DP05_0087E',\n",
       " 'DP05_0087M',\n",
       " 'DP05_0088E',\n",
       " 'DP05_0088M',\n",
       " 'DP05_0089E',\n",
       " 'DP05_0089M',\n",
       " 'DP05_0090E',\n",
       " 'DP05_0090M',\n",
       " 'DP05_0091E',\n",
       " 'DP05_0091M',\n",
       " 'DP05_0092E',\n",
       " 'DP05_0092M',\n",
       " 'DP05_0093E',\n",
       " 'DP05_0093M',\n",
       " 'DP05_0094E',\n",
       " 'DP05_0094M',\n",
       " 'DP05_0001PE',\n",
       " 'DP05_0001PM',\n",
       " 'DP05_0002PE',\n",
       " 'DP05_0002PM',\n",
       " 'DP05_0003PE',\n",
       " 'DP05_0003PM',\n",
       " 'DP05_0004PE',\n",
       " 'DP05_0004PM',\n",
       " 'DP05_0005PE',\n",
       " 'DP05_0005PM',\n",
       " 'DP05_0006PE',\n",
       " 'DP05_0006PM',\n",
       " 'DP05_0007PE',\n",
       " 'DP05_0007PM',\n",
       " 'DP05_0008PE',\n",
       " 'DP05_0008PM',\n",
       " 'DP05_0009PE',\n",
       " 'DP05_0009PM',\n",
       " 'DP05_0010PE',\n",
       " 'DP05_0010PM',\n",
       " 'DP05_0011PE',\n",
       " 'DP05_0011PM',\n",
       " 'DP05_0012PE',\n",
       " 'DP05_0012PM',\n",
       " 'DP05_0013PE',\n",
       " 'DP05_0013PM',\n",
       " 'DP05_0014PE',\n",
       " 'DP05_0014PM',\n",
       " 'DP05_0015PE',\n",
       " 'DP05_0015PM',\n",
       " 'DP05_0016PE',\n",
       " 'DP05_0016PM',\n",
       " 'DP05_0017PE',\n",
       " 'DP05_0017PM',\n",
       " 'DP05_0018PE',\n",
       " 'DP05_0018PM',\n",
       " 'DP05_0019PE',\n",
       " 'DP05_0019PM',\n",
       " 'DP05_0020PE',\n",
       " 'DP05_0020PM',\n",
       " 'DP05_0021PE',\n",
       " 'DP05_0021PM',\n",
       " 'DP05_0022PE',\n",
       " 'DP05_0022PM',\n",
       " 'DP05_0023PE',\n",
       " 'DP05_0023PM',\n",
       " 'DP05_0024PE',\n",
       " 'DP05_0024PM',\n",
       " 'DP05_0025PE',\n",
       " 'DP05_0025PM',\n",
       " 'DP05_0026PE',\n",
       " 'DP05_0026PM',\n",
       " 'DP05_0027PE',\n",
       " 'DP05_0027PM',\n",
       " 'DP05_0028PE',\n",
       " 'DP05_0028PM',\n",
       " 'DP05_0029PE',\n",
       " 'DP05_0029PM',\n",
       " 'DP05_0030PE',\n",
       " 'DP05_0030PM',\n",
       " 'DP05_0031PE',\n",
       " 'DP05_0031PM',\n",
       " 'DP05_0032PE',\n",
       " 'DP05_0032PM',\n",
       " 'DP05_0033PE',\n",
       " 'DP05_0033PM',\n",
       " 'DP05_0034PE',\n",
       " 'DP05_0034PM',\n",
       " 'DP05_0035PE',\n",
       " 'DP05_0035PM',\n",
       " 'DP05_0036PE',\n",
       " 'DP05_0036PM',\n",
       " 'DP05_0037PE',\n",
       " 'DP05_0037PM',\n",
       " 'DP05_0038PE',\n",
       " 'DP05_0038PM',\n",
       " 'DP05_0039PE',\n",
       " 'DP05_0039PM',\n",
       " 'DP05_0040PE',\n",
       " 'DP05_0040PM',\n",
       " 'DP05_0041PE',\n",
       " 'DP05_0041PM',\n",
       " 'DP05_0042PE',\n",
       " 'DP05_0042PM',\n",
       " 'DP05_0043PE',\n",
       " 'DP05_0043PM',\n",
       " 'DP05_0044PE',\n",
       " 'DP05_0044PM',\n",
       " 'DP05_0045PE',\n",
       " 'DP05_0045PM',\n",
       " 'DP05_0046PE',\n",
       " 'DP05_0046PM',\n",
       " 'DP05_0047PE',\n",
       " 'DP05_0047PM',\n",
       " 'DP05_0048PE',\n",
       " 'DP05_0048PM',\n",
       " 'DP05_0049PE',\n",
       " 'DP05_0049PM',\n",
       " 'DP05_0050PE',\n",
       " 'DP05_0050PM',\n",
       " 'DP05_0051PE',\n",
       " 'DP05_0051PM',\n",
       " 'DP05_0052PE',\n",
       " 'DP05_0052PM',\n",
       " 'DP05_0053PE',\n",
       " 'DP05_0053PM',\n",
       " 'DP05_0054PE',\n",
       " 'DP05_0054PM',\n",
       " 'DP05_0055PE',\n",
       " 'DP05_0055PM',\n",
       " 'DP05_0056PE',\n",
       " 'DP05_0056PM',\n",
       " 'DP05_0057PE',\n",
       " 'DP05_0057PM',\n",
       " 'DP05_0058PE',\n",
       " 'DP05_0058PM',\n",
       " 'DP05_0059PE',\n",
       " 'DP05_0059PM',\n",
       " 'DP05_0060PE',\n",
       " 'DP05_0060PM',\n",
       " 'DP05_0061PE',\n",
       " 'DP05_0061PM',\n",
       " 'DP05_0062PE',\n",
       " 'DP05_0062PM',\n",
       " 'DP05_0063PE',\n",
       " 'DP05_0063PM',\n",
       " 'DP05_0064PE',\n",
       " 'DP05_0064PM',\n",
       " 'DP05_0065PE',\n",
       " 'DP05_0065PM',\n",
       " 'DP05_0066PE',\n",
       " 'DP05_0066PM',\n",
       " 'DP05_0067PE',\n",
       " 'DP05_0067PM',\n",
       " 'DP05_0068PE',\n",
       " 'DP05_0068PM',\n",
       " 'DP05_0069PE',\n",
       " 'DP05_0069PM',\n",
       " 'DP05_0070PE',\n",
       " 'DP05_0070PM',\n",
       " 'DP05_0071PE',\n",
       " 'DP05_0071PM',\n",
       " 'DP05_0072PE',\n",
       " 'DP05_0072PM',\n",
       " 'DP05_0073PE',\n",
       " 'DP05_0073PM',\n",
       " 'DP05_0074PE',\n",
       " 'DP05_0074PM',\n",
       " 'DP05_0075PE',\n",
       " 'DP05_0075PM',\n",
       " 'DP05_0076PE',\n",
       " 'DP05_0076PM',\n",
       " 'DP05_0077PE',\n",
       " 'DP05_0077PM',\n",
       " 'DP05_0078PE',\n",
       " 'DP05_0078PM',\n",
       " 'DP05_0079PE',\n",
       " 'DP05_0079PM',\n",
       " 'DP05_0080PE',\n",
       " 'DP05_0080PM',\n",
       " 'DP05_0081PE',\n",
       " 'DP05_0081PM',\n",
       " 'DP05_0082PE',\n",
       " 'DP05_0082PM',\n",
       " 'DP05_0083PE',\n",
       " 'DP05_0083PM',\n",
       " 'DP05_0084PE',\n",
       " 'DP05_0084PM',\n",
       " 'DP05_0085PE',\n",
       " 'DP05_0085PM',\n",
       " 'DP05_0086PE',\n",
       " 'DP05_0086PM',\n",
       " 'DP05_0087PE',\n",
       " 'DP05_0087PM',\n",
       " 'DP05_0088PE',\n",
       " 'DP05_0088PM',\n",
       " 'DP05_0089PE',\n",
       " 'DP05_0089PM',\n",
       " 'DP05_0090PE',\n",
       " 'DP05_0090PM',\n",
       " 'DP05_0091PE',\n",
       " 'DP05_0091PM',\n",
       " 'DP05_0092PE',\n",
       " 'DP05_0092PM',\n",
       " 'DP05_0093PE',\n",
       " 'DP05_0093PM',\n",
       " 'DP05_0094PE',\n",
       " 'DP05_0094PM',\n",
       " 'Unnamed: 378']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(file_5.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8581405c-d64a-46fc-8869-641b0d6962f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GEO_ID', 'NAME', 'DP05_0001E', 'DP05_0001M', 'DP05_0002E', 'DP05_0002M', 'DP05_0003E', 'DP05_0003M', 'DP05_0004E', 'DP05_0004M', 'DP05_0005E', 'DP05_0005M', 'DP05_0006E', 'DP05_0006M', 'DP05_0007E', 'DP05_0007M', 'DP05_0008E', 'DP05_0008M', 'DP05_0009E', 'DP05_0009M', 'DP05_0010E', 'DP05_0010M', 'DP05_0011E', 'DP05_0011M', 'DP05_0012E', 'DP05_0012M', 'DP05_0013E', 'DP05_0013M', 'DP05_0014E', 'DP05_0014M', 'DP05_0015E', 'DP05_0015M', 'DP05_0016E', 'DP05_0016M', 'DP05_0017E', 'DP05_0017M', 'DP05_0018E', 'DP05_0018M', 'DP05_0019E', 'DP05_0019M', 'DP05_0020E', 'DP05_0020M', 'DP05_0021E', 'DP05_0021M', 'DP05_0022E', 'DP05_0022M', 'DP05_0023E', 'DP05_0023M', 'DP05_0024E', 'DP05_0024M', 'DP05_0025E', 'DP05_0025M', 'DP05_0026E', 'DP05_0026M', 'DP05_0027E', 'DP05_0027M', 'DP05_0028E', 'DP05_0028M', 'DP05_0029E', 'DP05_0029M', 'DP05_0030E', 'DP05_0030M', 'DP05_0031E', 'DP05_0031M', 'DP05_0032E', 'DP05_0032M', 'DP05_0033E', 'DP05_0033M', 'DP05_0034E', 'DP05_0034M', 'DP05_0035E', 'DP05_0035M', 'DP05_0036E', 'DP05_0036M', 'DP05_0037E', 'DP05_0037M', 'DP05_0038E', 'DP05_0038M', 'DP05_0039E', 'DP05_0039M', 'DP05_0040E', 'DP05_0040M', 'DP05_0041E', 'DP05_0041M', 'DP05_0042E', 'DP05_0042M', 'DP05_0043E', 'DP05_0043M', 'DP05_0044E', 'DP05_0044M', 'DP05_0045E', 'DP05_0045M', 'DP05_0046E', 'DP05_0046M', 'DP05_0047E', 'DP05_0047M', 'DP05_0048E', 'DP05_0048M', 'DP05_0049E', 'DP05_0049M', 'DP05_0050E', 'DP05_0050M', 'DP05_0051E', 'DP05_0051M', 'DP05_0052E', 'DP05_0052M', 'DP05_0053E', 'DP05_0053M', 'DP05_0054E', 'DP05_0054M', 'DP05_0055E', 'DP05_0055M', 'DP05_0056E', 'DP05_0056M', 'DP05_0057E', 'DP05_0057M', 'DP05_0058E', 'DP05_0058M', 'DP05_0059E', 'DP05_0059M', 'DP05_0060E', 'DP05_0060M', 'DP05_0061E', 'DP05_0061M', 'DP05_0062E', 'DP05_0062M', 'DP05_0063E', 'DP05_0063M', 'DP05_0064E', 'DP05_0064M', 'DP05_0065E', 'DP05_0065M', 'DP05_0066E', 'DP05_0066M', 'DP05_0067E', 'DP05_0067M', 'DP05_0068E', 'DP05_0068M', 'DP05_0069E', 'DP05_0069M', 'DP05_0070E', 'DP05_0070M', 'DP05_0071E', 'DP05_0071M', 'DP05_0072E', 'DP05_0072M', 'DP05_0073E', 'DP05_0073M', 'DP05_0074E', 'DP05_0074M', 'DP05_0075E', 'DP05_0075M', 'DP05_0076E', 'DP05_0076M', 'DP05_0077E', 'DP05_0077M', 'DP05_0078E', 'DP05_0078M', 'DP05_0079E', 'DP05_0079M', 'DP05_0080E', 'DP05_0080M', 'DP05_0081E', 'DP05_0081M', 'DP05_0082E', 'DP05_0082M', 'DP05_0083E', 'DP05_0083M', 'DP05_0084E', 'DP05_0084M', 'DP05_0085E', 'DP05_0085M', 'DP05_0086E', 'DP05_0086M', 'DP05_0087E', 'DP05_0087M', 'DP05_0088E', 'DP05_0088M', 'DP05_0089E', 'DP05_0089M', 'DP05_0090E', 'DP05_0090M', 'DP05_0091E', 'DP05_0091M', 'DP05_0092E', 'DP05_0092M', 'DP05_0093E', 'DP05_0093M', 'DP05_0094E', 'DP05_0094M', 'DP05_0001PE', 'DP05_0001PM', 'DP05_0002PE', 'DP05_0002PM', 'DP05_0003PE', 'DP05_0003PM', 'DP05_0004PE', 'DP05_0004PM', 'DP05_0005PE', 'DP05_0005PM', 'DP05_0006PE', 'DP05_0006PM', 'DP05_0007PE', 'DP05_0007PM', 'DP05_0008PE', 'DP05_0008PM', 'DP05_0009PE', 'DP05_0009PM', 'DP05_0010PE', 'DP05_0010PM', 'DP05_0011PE', 'DP05_0011PM', 'DP05_0012PE', 'DP05_0012PM', 'DP05_0013PE', 'DP05_0013PM', 'DP05_0014PE', 'DP05_0014PM', 'DP05_0015PE', 'DP05_0015PM', 'DP05_0016PE', 'DP05_0016PM', 'DP05_0017PE', 'DP05_0017PM', 'DP05_0018PE', 'DP05_0018PM', 'DP05_0019PE', 'DP05_0019PM', 'DP05_0020PE', 'DP05_0020PM', 'DP05_0021PE', 'DP05_0021PM', 'DP05_0022PE', 'DP05_0022PM', 'DP05_0023PE', 'DP05_0023PM', 'DP05_0024PE', 'DP05_0024PM', 'DP05_0025PE', 'DP05_0025PM', 'DP05_0026PE', 'DP05_0026PM', 'DP05_0027PE', 'DP05_0027PM', 'DP05_0028PE', 'DP05_0028PM', 'DP05_0029PE', 'DP05_0029PM', 'DP05_0030PE', 'DP05_0030PM', 'DP05_0031PE', 'DP05_0031PM', 'DP05_0032PE', 'DP05_0032PM', 'DP05_0033PE', 'DP05_0033PM', 'DP05_0034PE', 'DP05_0034PM', 'DP05_0035PE', 'DP05_0035PM', 'DP05_0036PE', 'DP05_0036PM', 'DP05_0037PE', 'DP05_0037PM', 'DP05_0038PE', 'DP05_0038PM', 'DP05_0039PE', 'DP05_0039PM', 'DP05_0040PE', 'DP05_0040PM', 'DP05_0041PE', 'DP05_0041PM', 'DP05_0042PE', 'DP05_0042PM', 'DP05_0043PE', 'DP05_0043PM', 'DP05_0044PE', 'DP05_0044PM', 'DP05_0045PE', 'DP05_0045PM', 'DP05_0046PE', 'DP05_0046PM', 'DP05_0047PE', 'DP05_0047PM', 'DP05_0048PE', 'DP05_0048PM', 'DP05_0049PE', 'DP05_0049PM', 'DP05_0050PE', 'DP05_0050PM', 'DP05_0051PE', 'DP05_0051PM', 'DP05_0052PE', 'DP05_0052PM', 'DP05_0053PE', 'DP05_0053PM', 'DP05_0054PE', 'DP05_0054PM', 'DP05_0055PE', 'DP05_0055PM', 'DP05_0056PE', 'DP05_0056PM', 'DP05_0057PE', 'DP05_0057PM', 'DP05_0058PE', 'DP05_0058PM', 'DP05_0059PE', 'DP05_0059PM', 'DP05_0060PE', 'DP05_0060PM', 'DP05_0061PE', 'DP05_0061PM', 'DP05_0062PE', 'DP05_0062PM', 'DP05_0063PE', 'DP05_0063PM', 'DP05_0064PE', 'DP05_0064PM', 'DP05_0065PE', 'DP05_0065PM', 'DP05_0066PE', 'DP05_0066PM', 'DP05_0067PE', 'DP05_0067PM', 'DP05_0068PE', 'DP05_0068PM', 'DP05_0069PE', 'DP05_0069PM', 'DP05_0070PE', 'DP05_0070PM', 'DP05_0071PE', 'DP05_0071PM', 'DP05_0072PE', 'DP05_0072PM', 'DP05_0073PE', 'DP05_0073PM', 'DP05_0074PE', 'DP05_0074PM', 'DP05_0075PE', 'DP05_0075PM', 'DP05_0076PE', 'DP05_0076PM', 'DP05_0077PE', 'DP05_0077PM', 'DP05_0078PE', 'DP05_0078PM', 'DP05_0079PE', 'DP05_0079PM', 'DP05_0080PE', 'DP05_0080PM', 'DP05_0081PE', 'DP05_0081PM', 'DP05_0082PE', 'DP05_0082PM', 'DP05_0083PE', 'DP05_0083PM', 'DP05_0084PE', 'DP05_0084PM', 'DP05_0085PE', 'DP05_0085PM', 'DP05_0086PE', 'DP05_0086PM', 'DP05_0087PE', 'DP05_0087PM', 'DP05_0088PE', 'DP05_0088PM', 'DP05_0089PE', 'DP05_0089PM', 'DP05_0090PE', 'DP05_0090PM', 'DP05_0091PE', 'DP05_0091PM', 'DP05_0092PE', 'DP05_0092PM', 'DP05_0093PE', 'DP05_0093PM', 'DP05_0094PE', 'DP05_0094PM']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tt/mzspvn2d7hb3qsps4c4lqh0c0000gn/T/ipykernel_19118/1577892894.py:2: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  all_numeric = file_5.applymap(lambda x: isinstance(x, (int, float))).all()\n"
     ]
    }
   ],
   "source": [
    "# Check if all values in each column are numeric\n",
    "all_numeric = file_5.applymap(lambda x: isinstance(x, (int, float))).all()\n",
    "\n",
    "# List of columns that are not fully numeric\n",
    "non_numeric_columns = all_numeric[all_numeric == False].index.tolist()\n",
    "print(non_numeric_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d32b810-8b2d-41e1-862f-7d8f4105d956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split 'NAME' into 'County' and 'State'\n",
    "file_5[['County', 'State']] = file_5['NAME'].str.split(', ', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "95c28ffb-4e0c-4bb6-a19d-06bd44f8b534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude only NAME, County, and State\n",
    "exclude_cols = ['NAME', 'County', 'State']\n",
    "\n",
    "# Identify all other columns to convert\n",
    "cols_to_convert = file_5.columns.difference(exclude_cols)\n",
    "\n",
    "# Convert them to numeric\n",
    "file_5[cols_to_convert] = file_5[cols_to_convert].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b1dd82c-510d-4d1b-9540-ec027d840c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GEO_ID          float64\n",
       "NAME             object\n",
       "DP05_0001E      float64\n",
       "DP05_0001M      float64\n",
       "DP05_0002E      float64\n",
       "                 ...   \n",
       "DP05_0094PE     float64\n",
       "DP05_0094PM     float64\n",
       "Unnamed: 378    float64\n",
       "County           object\n",
       "State            object\n",
       "Length: 381, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_5.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea2fc76a-298a-49af-9ba1-acf6ab02bc87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tt/mzspvn2d7hb3qsps4c4lqh0c0000gn/T/ipykernel_19118/1385975680.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  file_5[\"Young_Children\"] = file_5[\"DP05_0005E\"]  # Age 04\n",
      "/var/folders/tt/mzspvn2d7hb3qsps4c4lqh0c0000gn/T/ipykernel_19118/1385975680.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  file_5[\"Children\"] = file_5[\"DP05_0006E\"] + file_5[\"DP05_0007E\"]  # Ages 514\n",
      "/var/folders/tt/mzspvn2d7hb3qsps4c4lqh0c0000gn/T/ipykernel_19118/1385975680.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  file_5[\"Adolescents\"] = file_5[\"DP05_0008E\"]  # Ages 1519\n",
      "/var/folders/tt/mzspvn2d7hb3qsps4c4lqh0c0000gn/T/ipykernel_19118/1385975680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  file_5[\"Young_Adults\"] = file_5[\"DP05_0009E\"]  # Ages 2024\n",
      "/var/folders/tt/mzspvn2d7hb3qsps4c4lqh0c0000gn/T/ipykernel_19118/1385975680.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  file_5[\"Emerging_Workforce\"] = file_5[\"DP05_0010E\"]  # Ages 2534\n",
      "/var/folders/tt/mzspvn2d7hb3qsps4c4lqh0c0000gn/T/ipykernel_19118/1385975680.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  file_5[\"Prime_Working_Age\"] = file_5[\"DP05_0011E\"] + file_5[\"DP05_0012E\"]  # Ages 3554\n",
      "/var/folders/tt/mzspvn2d7hb3qsps4c4lqh0c0000gn/T/ipykernel_19118/1385975680.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  file_5[\"Pre_Retirement\"] = file_5[\"DP05_0013E\"] + file_5[\"DP05_0014E\"]  # Ages 5564\n",
      "/var/folders/tt/mzspvn2d7hb3qsps4c4lqh0c0000gn/T/ipykernel_19118/1385975680.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  file_5[\"Seniors\"] = (\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>County</th>\n",
       "      <th>State</th>\n",
       "      <th>Young_Children</th>\n",
       "      <th>Children</th>\n",
       "      <th>Adolescents</th>\n",
       "      <th>Young_Adults</th>\n",
       "      <th>Emerging_Workforce</th>\n",
       "      <th>Prime_Working_Age</th>\n",
       "      <th>Pre_Retirement</th>\n",
       "      <th>Seniors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Geographic Area Name</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>3430.0</td>\n",
       "      <td>7749.0</td>\n",
       "      <td>3922.0</td>\n",
       "      <td>3417.0</td>\n",
       "      <td>7605.0</td>\n",
       "      <td>15806.0</td>\n",
       "      <td>7882.0</td>\n",
       "      <td>9474.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Baldwin County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>12448.0</td>\n",
       "      <td>29231.0</td>\n",
       "      <td>14603.0</td>\n",
       "      <td>11675.0</td>\n",
       "      <td>26412.0</td>\n",
       "      <td>59732.0</td>\n",
       "      <td>34518.0</td>\n",
       "      <td>51326.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Barbour County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1380.0</td>\n",
       "      <td>2885.0</td>\n",
       "      <td>1425.0</td>\n",
       "      <td>1439.0</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>6058.0</td>\n",
       "      <td>3289.0</td>\n",
       "      <td>4881.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bibb County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1069.0</td>\n",
       "      <td>2608.0</td>\n",
       "      <td>1348.0</td>\n",
       "      <td>1196.0</td>\n",
       "      <td>3111.0</td>\n",
       "      <td>6050.0</td>\n",
       "      <td>3014.0</td>\n",
       "      <td>3756.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 County    State  Young_Children  Children  Adolescents  \\\n",
       "0  Geographic Area Name     None             NaN       NaN          NaN   \n",
       "1        Autauga County  Alabama          3430.0    7749.0       3922.0   \n",
       "2        Baldwin County  Alabama         12448.0   29231.0      14603.0   \n",
       "3        Barbour County  Alabama          1380.0    2885.0       1425.0   \n",
       "4           Bibb County  Alabama          1069.0    2608.0       1348.0   \n",
       "\n",
       "   Young_Adults  Emerging_Workforce  Prime_Working_Age  Pre_Retirement  \\\n",
       "0           NaN                 NaN                NaN             NaN   \n",
       "1        3417.0              7605.0            15806.0          7882.0   \n",
       "2       11675.0             26412.0            59732.0         34518.0   \n",
       "3        1439.0              3400.0             6058.0          3289.0   \n",
       "4        1196.0              3111.0             6050.0          3014.0   \n",
       "\n",
       "   Seniors  \n",
       "0      NaN  \n",
       "1   9474.0  \n",
       "2  51326.0  \n",
       "3   4881.0  \n",
       "4   3756.0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create grouped age categories based on federal-aligned brackets\n",
    "file_5[\"Young_Children\"] = file_5[\"DP05_0005E\"]  # Age 04\n",
    "file_5[\"Children\"] = file_5[\"DP05_0006E\"] + file_5[\"DP05_0007E\"]  # Ages 514\n",
    "file_5[\"Adolescents\"] = file_5[\"DP05_0008E\"]  # Ages 1519\n",
    "file_5[\"Young_Adults\"] = file_5[\"DP05_0009E\"]  # Ages 2024\n",
    "file_5[\"Emerging_Workforce\"] = file_5[\"DP05_0010E\"]  # Ages 2534\n",
    "file_5[\"Prime_Working_Age\"] = file_5[\"DP05_0011E\"] + file_5[\"DP05_0012E\"]  # Ages 3554\n",
    "file_5[\"Pre_Retirement\"] = file_5[\"DP05_0013E\"] + file_5[\"DP05_0014E\"]  # Ages 5564\n",
    "file_5[\"Seniors\"] = (\n",
    "    file_5[\"DP05_0015E\"] + file_5[\"DP05_0016E\"] + file_5[\"DP05_0017E\"]\n",
    ")  # Ages 65+\n",
    "\n",
    "# Preview the new age group columns to confirm they were created correctly\n",
    "file_5[[\n",
    "    \"County\", \"State\",\n",
    "    \"Young_Children\", \"Children\", \"Adolescents\", \"Young_Adults\",\n",
    "    \"Emerging_Workforce\", \"Prime_Working_Age\",\n",
    "    \"Pre_Retirement\", \"Seniors\"\n",
    "]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "52897fce-6d36-4515-9120-846b62184d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tt/mzspvn2d7hb3qsps4c4lqh0c0000gn/T/ipykernel_19118/3509463110.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  file_5[\"Diversity_Index\"] = 1 - (race_proportions ** 2).sum(axis=1)\n"
     ]
    }
   ],
   "source": [
    "# Define race columns and total population column\n",
    "race_cols = [\n",
    "    \"DP05_0082E\",  # White\n",
    "    \"DP05_0088E\",  # Black\n",
    "    \"DP05_0089E\",  # AIAN\n",
    "    \"DP05_0090E\",  # Asian\n",
    "    \"DP05_0091E\",  # NHPI\n",
    "    \"DP05_0092E\",  # Some Other Race\n",
    "    \"DP05_0093E\",  # Two or More Races\n",
    "]\n",
    "\n",
    "# Calculate proportions (p)\n",
    "race_proportions = file_5[race_cols].div(file_5[\"DP05_0001E\"], axis=0)\n",
    "\n",
    "# Calculate Diversity Index = 1 - sum(p)\n",
    "file_5[\"Diversity_Index\"] = 1 - (race_proportions ** 2).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f882d4b-cb91-44d0-ac4c-58e2da079b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>County</th>\n",
       "      <th>State</th>\n",
       "      <th>DP05_0001E</th>\n",
       "      <th>DP05_0082E</th>\n",
       "      <th>DP05_0088E</th>\n",
       "      <th>DP05_0089E</th>\n",
       "      <th>DP05_0090E</th>\n",
       "      <th>DP05_0091E</th>\n",
       "      <th>DP05_0092E</th>\n",
       "      <th>DP05_0093E</th>\n",
       "      <th>Diversity_Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Geographic Area Name</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>59285.0</td>\n",
       "      <td>42497.0</td>\n",
       "      <td>1912.0</td>\n",
       "      <td>397.0</td>\n",
       "      <td>1515.0</td>\n",
       "      <td>24731.0</td>\n",
       "      <td>44761.0</td>\n",
       "      <td>21386.0</td>\n",
       "      <td>-0.389768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Baldwin County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>239945.0</td>\n",
       "      <td>195347.0</td>\n",
       "      <td>8248.0</td>\n",
       "      <td>1594.0</td>\n",
       "      <td>6654.0</td>\n",
       "      <td>128518.0</td>\n",
       "      <td>184665.0</td>\n",
       "      <td>88784.0</td>\n",
       "      <td>-0.680908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Barbour County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>24757.0</td>\n",
       "      <td>10807.0</td>\n",
       "      <td>381.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>11702.0</td>\n",
       "      <td>19201.0</td>\n",
       "      <td>10230.0</td>\n",
       "      <td>-0.186656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bibb County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>22152.0</td>\n",
       "      <td>16333.0</td>\n",
       "      <td>395.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>351.0</td>\n",
       "      <td>9090.0</td>\n",
       "      <td>17469.0</td>\n",
       "      <td>9352.0</td>\n",
       "      <td>-0.512707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Blount County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>59292.0</td>\n",
       "      <td>50374.0</td>\n",
       "      <td>1876.0</td>\n",
       "      <td>575.0</td>\n",
       "      <td>1301.0</td>\n",
       "      <td>24793.0</td>\n",
       "      <td>43866.0</td>\n",
       "      <td>21697.0</td>\n",
       "      <td>-0.579490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bullock County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>10157.0</td>\n",
       "      <td>2143.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>4554.0</td>\n",
       "      <td>7847.0</td>\n",
       "      <td>4292.0</td>\n",
       "      <td>-0.021326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Butler County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>18807.0</td>\n",
       "      <td>9531.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>9841.0</td>\n",
       "      <td>14452.0</td>\n",
       "      <td>6543.0</td>\n",
       "      <td>-0.242477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Calhoun County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>116141.0</td>\n",
       "      <td>81098.0</td>\n",
       "      <td>3176.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>2866.0</td>\n",
       "      <td>53271.0</td>\n",
       "      <td>89916.0</td>\n",
       "      <td>42639.0</td>\n",
       "      <td>-0.433497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chambers County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>34450.0</td>\n",
       "      <td>18575.0</td>\n",
       "      <td>616.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>536.0</td>\n",
       "      <td>16427.0</td>\n",
       "      <td>26764.0</td>\n",
       "      <td>12398.0</td>\n",
       "      <td>-0.251743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 County    State  DP05_0001E  DP05_0082E  DP05_0088E  \\\n",
       "0  Geographic Area Name     None         NaN         NaN         NaN   \n",
       "1        Autauga County  Alabama     59285.0     42497.0      1912.0   \n",
       "2        Baldwin County  Alabama    239945.0    195347.0      8248.0   \n",
       "3        Barbour County  Alabama     24757.0     10807.0       381.0   \n",
       "4           Bibb County  Alabama     22152.0     16333.0       395.0   \n",
       "5         Blount County  Alabama     59292.0     50374.0      1876.0   \n",
       "6        Bullock County  Alabama     10157.0      2143.0       156.0   \n",
       "7         Butler County  Alabama     18807.0      9531.0       239.0   \n",
       "8        Calhoun County  Alabama    116141.0     81098.0      3176.0   \n",
       "9       Chambers County  Alabama     34450.0     18575.0       616.0   \n",
       "\n",
       "   DP05_0089E  DP05_0090E  DP05_0091E  DP05_0092E  DP05_0093E  Diversity_Index  \n",
       "0         NaN         NaN         NaN         NaN         NaN         1.000000  \n",
       "1       397.0      1515.0     24731.0     44761.0     21386.0        -0.389768  \n",
       "2      1594.0      6654.0    128518.0    184665.0     88784.0        -0.680908  \n",
       "3        58.0       323.0     11702.0     19201.0     10230.0        -0.186656  \n",
       "4        44.0       351.0      9090.0     17469.0      9352.0        -0.512707  \n",
       "5       575.0      1301.0     24793.0     43866.0     21697.0        -0.579490  \n",
       "6        67.0        89.0      4554.0      7847.0      4292.0        -0.021326  \n",
       "7         5.0       234.0      9841.0     14452.0      6543.0        -0.242477  \n",
       "8       310.0      2866.0     53271.0     89916.0     42639.0        -0.433497  \n",
       "9        80.0       536.0     16427.0     26764.0     12398.0        -0.251743  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show selected columns + Diversity Index for first 10 rows\n",
    "file_5.loc[:, [\n",
    "    \"County\", \"State\", \"DP05_0001E\",  # Total population\n",
    "    \"DP05_0082E\", \"DP05_0088E\", \"DP05_0089E\",  # White, Black, AIAN\n",
    "    \"DP05_0090E\", \"DP05_0091E\", \"DP05_0092E\", \"DP05_0093E\",  # Asian, NHPI, Other, 2+\n",
    "    \"Diversity_Index\"\n",
    "]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3ebc1e23-b9b1-411b-b631-e2cc6216708e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      NAME  total_population  DP05_0037E  DP05_0038E  \\\n",
      "0     Geographic Area Name               NaN         NaN         NaN   \n",
      "1  Autauga County, Alabama           59285.0    0.735700    0.199528   \n",
      "2  Baldwin County, Alabama          239945.0    0.828194    0.079785   \n",
      "3  Barbour County, Alabama           24757.0    0.439916    0.469201   \n",
      "4     Bibb County, Alabama           22152.0    0.750903    0.207069   \n",
      "\n",
      "   DP05_0039E  DP05_0047E  DP05_0055E  DP05_0060E  DP05_0061E  \n",
      "0         NaN         NaN         NaN         NaN         NaN  \n",
      "1    0.000708    0.010390    0.000000    0.007759    0.045914  \n",
      "2    0.004084    0.009469    0.000433    0.022672    0.055363  \n",
      "3    0.001858    0.005493    0.000000    0.054005    0.029527  \n",
      "4    0.007900    0.002302    0.000000    0.003611    0.028214  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tt/mzspvn2d7hb3qsps4c4lqh0c0000gn/T/ipykernel_19118/4219069668.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  file_5['total_population'] = file_5['DP05_0001E']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of race/ethnicity columns you want to calculate proportions for\n",
    "race_columns = [\n",
    "    \"DP05_0037E\",  # White alone\n",
    "    \"DP05_0038E\",  # Black or African American alone\n",
    "    \"DP05_0039E\",  # American Indian and Alaska Native alone\n",
    "    \"DP05_0047E\",  # Asian alone\n",
    "    \"DP05_0055E\",  # Native Hawaiian and Other Pacific Islander alone\n",
    "    \"DP05_0060E\",  # Some Other Race alone\n",
    "    \"DP05_0061E\"   # Two or More Races\n",
    "]\n",
    "\n",
    "# Assuming 'file_5' is your DataFrame, and 'DP05_0001E' is the total population column\n",
    "file_5['total_population'] = file_5['DP05_0001E']\n",
    "\n",
    "# Calculate proportions for each group by dividing by the total population\n",
    "proportions = file_5[race_columns].div(file_5['total_population'], axis=0)\n",
    "\n",
    "# Add proportions to your DataFrame for reference\n",
    "file_5_proportions = pd.concat([file_5[['NAME', 'total_population']], proportions], axis=1)\n",
    "\n",
    "# Show the first 5 rows to check the results\n",
    "print(file_5_proportions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "82af33c7-73ef-40eb-b5f1-e6e171e368c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      NAME  Race_Sum\n",
      "0     Geographic Area Name       0.0\n",
      "1  Autauga County, Alabama   59285.0\n",
      "2  Baldwin County, Alabama  239945.0\n",
      "3  Barbour County, Alabama   24757.0\n",
      "4     Bibb County, Alabama   22152.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tt/mzspvn2d7hb3qsps4c4lqh0c0000gn/T/ipykernel_19118/522555291.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  file_5['Race_Sum'] = file_5[race_columns].sum(axis=1)\n"
     ]
    }
   ],
   "source": [
    "# List of race/ethnicity columns\n",
    "race_columns = [\n",
    "    \"DP05_0037E\",  # White alone\n",
    "    \"DP05_0038E\",  # Black or African American alone\n",
    "    \"DP05_0039E\",  # American Indian and Alaska Native alone\n",
    "    \"DP05_0047E\",  # Asian alone\n",
    "    \"DP05_0055E\",  # Native Hawaiian and Other Pacific Islander alone\n",
    "    \"DP05_0060E\",  # Some Other Race alone\n",
    "    \"DP05_0061E\"   # Two or More Races\n",
    "]\n",
    "\n",
    "# Assuming 'file_5' is your DataFrame and 'total_population' is already added\n",
    "# Calculate the sum of these 7 columns for each row\n",
    "file_5['Race_Sum'] = file_5[race_columns].sum(axis=1)\n",
    "\n",
    "# Show the first 5 rows with the sum included\n",
    "print(file_5[['NAME', 'Race_Sum']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "648438d2-9b23-4ce6-a0b8-1d85b88d9ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      NAME  total_population  Diversity_Index  DP05_0037E  \\\n",
      "0     Geographic Area Name               NaN         1.000000         NaN   \n",
      "1  Autauga County, Alabama           59285.0         0.416657    0.735700   \n",
      "2  Baldwin County, Alabama          239945.0         0.304044    0.828194   \n",
      "3  Barbour County, Alabama           24757.0         0.582503    0.439916   \n",
      "4     Bibb County, Alabama           22152.0         0.392390    0.750903   \n",
      "\n",
      "   DP05_0038E  DP05_0039E  DP05_0047E  DP05_0055E  DP05_0060E  DP05_0061E  \n",
      "0         NaN         NaN         NaN         NaN         NaN         NaN  \n",
      "1    0.199528    0.000708    0.010390    0.000000    0.007759    0.045914  \n",
      "2    0.079785    0.004084    0.009469    0.000433    0.022672    0.055363  \n",
      "3    0.469201    0.001858    0.005493    0.000000    0.054005    0.029527  \n",
      "4    0.207069    0.007900    0.002302    0.000000    0.003611    0.028214  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of race/ethnicity columns you want to calculate proportions for\n",
    "race_columns = [\n",
    "    \"DP05_0037E\",  # White alone\n",
    "    \"DP05_0038E\",  # Black or African American alone\n",
    "    \"DP05_0039E\",  # American Indian and Alaska Native alone\n",
    "    \"DP05_0047E\",  # Asian alone\n",
    "    \"DP05_0055E\",  # Native Hawaiian and Other Pacific Islander alone\n",
    "    \"DP05_0060E\",  # Some Other Race alone\n",
    "    \"DP05_0061E\"   # Two or More Races\n",
    "]\n",
    "\n",
    "# Assuming 'file_5' is your DataFrame, and 'DP05_0001E' is the total population column\n",
    "file_5['total_population'] = file_5['DP05_0001E']\n",
    "\n",
    "# Calculate proportions for each group by dividing by the total population\n",
    "proportions = file_5[race_columns].div(file_5['total_population'], axis=0)\n",
    "\n",
    "# Calculate the diversity index (1 - sum of squared proportions)\n",
    "file_5['Diversity_Index'] = 1 - (proportions ** 2).sum(axis=1)\n",
    "\n",
    "# Add the calculated proportions to your DataFrame for reference\n",
    "file_5_proportions = pd.concat([file_5[['NAME', 'total_population', 'Diversity_Index']], proportions], axis=1)\n",
    "\n",
    "# Show the first 5 rows to check the results\n",
    "print(file_5_proportions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1c3d7dde-c323-4e56-8196-dfe839ad9b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    NAME  Diversity_Index\n",
      "68        Aleutians East Borough, Alaska         0.772724\n",
      "69    Aleutians West Census Area, Alaska         0.742459\n",
      "96      Yakutat City and Borough, Alaska         0.783523\n",
      "188           Alameda County, California         0.754334\n",
      "228         San Mateo County, California         0.709837\n",
      "230       Santa Clara County, California         0.704553\n",
      "235            Solano County, California         0.739284\n",
      "456             Gwinnett County, Georgia         0.747795\n",
      "549                Hawaii County, Hawaii         0.737169\n",
      "550              Honolulu County, Hawaii         0.713127\n",
      "552                 Kauai County, Hawaii         0.733950\n",
      "553                  Maui County, Hawaii         0.738591\n",
      "1854              Kings County, New York         0.729029\n",
      "1871             Queens County, New York         0.782643\n",
      "1970      Robeson County, North Carolina         0.719702\n",
      "2582                Dallas County, Texas         0.734338\n",
      "2604             Fort Bend County, Texas         0.750012\n",
      "2938        Manassas Park city, Virginia         0.753955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tt/mzspvn2d7hb3qsps4c4lqh0c0000gn/T/ipykernel_19118/1478746332.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_file_5['total_population'] = filtered_file_5['DP05_0001E']\n",
      "/var/folders/tt/mzspvn2d7hb3qsps4c4lqh0c0000gn/T/ipykernel_19118/1478746332.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_file_5['Diversity_Index'] = 1 - (proportions ** 2).sum(axis=1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of race/ethnicity columns you want to calculate proportions for\n",
    "race_columns = [\n",
    "    \"DP05_0037E\",  # White alone\n",
    "    \"DP05_0038E\",  # Black or African American alone\n",
    "    \"DP05_0039E\",  # American Indian and Alaska Native alone\n",
    "    \"DP05_0047E\",  # Asian alone\n",
    "    \"DP05_0055E\",  # Native Hawaiian and Other Pacific Islander alone\n",
    "    \"DP05_0060E\",  # Some Other Race alone\n",
    "    \"DP05_0061E\"   # Two or More Races\n",
    "]\n",
    "\n",
    "# List of counties and areas to filter (updated to match the format)\n",
    "counties = [\n",
    "    \"Aleutians West Census Area, Alaska\",\n",
    "    \"Queens County, New York\",\n",
    "    \"Maui County, Hawaii\",\n",
    "    \"Alameda County, California\",\n",
    "    \"Aleutians East Borough, Alaska\",\n",
    "    \"Hawaii County, Hawaii\",\n",
    "    \"Fort Bend County, Texas\",\n",
    "    \"Hawaii\",\n",
    "    \"Kauai County, Hawaii\",\n",
    "    \"Solano County, California\",\n",
    "    \"Honolulu County, Hawaii\",\n",
    "    \"Robeson County, North Carolina\",\n",
    "    \"Gwinnett County, Georgia\",\n",
    "    \"Yakutat City and Borough, Alaska\",\n",
    "    \"Santa Clara County, California\",\n",
    "    \"Kings County, New York\",\n",
    "    \"San Mateo County, California\",\n",
    "    \"Manassas Park city, Virginia\",\n",
    "    \"Dallas County, Texas\"\n",
    "]\n",
    "\n",
    "# Filter the file_5 DataFrame for the specified counties\n",
    "filtered_file_5 = file_5[file_5['NAME'].isin(counties)]\n",
    "\n",
    "# Assuming 'DP05_0001E' is the total population column\n",
    "filtered_file_5['total_population'] = filtered_file_5['DP05_0001E']\n",
    "\n",
    "# Calculate proportions for each group by dividing by the total population\n",
    "proportions = filtered_file_5[race_columns].div(filtered_file_5['total_population'], axis=0)\n",
    "\n",
    "# Calculate the diversity index (1 - sum of squared proportions)\n",
    "filtered_file_5['Diversity_Index'] = 1 - (proportions ** 2).sum(axis=1)\n",
    "\n",
    "# Add the calculated proportions to the DataFrame for reference\n",
    "filtered_file_5_proportions = pd.concat([filtered_file_5[['NAME', 'total_population', 'Diversity_Index']], proportions], axis=1)\n",
    "\n",
    "# Show the first 5 rows to check the results\n",
    "print(filtered_file_5_proportions[['NAME', 'Diversity_Index']].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "26941179-5336-45b3-bf1d-b515ed721c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      NAME  Hispanic_percentage  Non_Hispanic_percentage  \\\n",
      "0     Geographic Area Name                  NaN                      NaN   \n",
      "1  Autauga County, Alabama             3.690647                96.309353   \n",
      "2  Baldwin County, Alabama             5.581696                94.418304   \n",
      "3  Barbour County, Alabama             6.018500                93.981500   \n",
      "4     Bibb County, Alabama             3.358613                96.641387   \n",
      "\n",
      "   check_sum  \n",
      "0        NaN  \n",
      "1      100.0  \n",
      "2      100.0  \n",
      "3      100.0  \n",
      "4      100.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tt/mzspvn2d7hb3qsps4c4lqh0c0000gn/T/ipykernel_19118/3738283183.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  file_5['Hispanic_percentage'] = (file_5['DP05_0076E'] * 100) / file_5['DP05_0075E']\n",
      "/var/folders/tt/mzspvn2d7hb3qsps4c4lqh0c0000gn/T/ipykernel_19118/3738283183.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  file_5['Non_Hispanic_percentage'] = (file_5['DP05_0081E'] * 100) / file_5['DP05_0075E']\n",
      "/var/folders/tt/mzspvn2d7hb3qsps4c4lqh0c0000gn/T/ipykernel_19118/3738283183.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  file_5['check_sum'] = file_5['Hispanic_percentage'] + file_5['Non_Hispanic_percentage']\n"
     ]
    }
   ],
   "source": [
    "# Calculate the Hispanic and Non-Hispanic percentages using the formula\n",
    "file_5['Hispanic_percentage'] = (file_5['DP05_0076E'] * 100) / file_5['DP05_0075E']\n",
    "file_5['Non_Hispanic_percentage'] = (file_5['DP05_0081E'] * 100) / file_5['DP05_0075E']\n",
    "\n",
    "# Check the result to make sure the sum of both percentages equals 100\n",
    "file_5['check_sum'] = file_5['Hispanic_percentage'] + file_5['Non_Hispanic_percentage']\n",
    "\n",
    "# Show the updated DataFrame with the calculated percentages\n",
    "print(file_5[['NAME', 'Hispanic_percentage', 'Non_Hispanic_percentage', 'check_sum']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3b4e0a6f-eaa9-4c71-b25d-3aef9c8ba069",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_5_selected = file_5.copy()  # create a working copy of file_5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9cf4a1f2-d1ee-4312-9fe6-a8cffe5281a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " File saved successfully at: /Users/emilsafarov/Library/CloudStorage/OneDrive-Personal/CF/A6/1_sourceing_open_data/US project/Data/Output data/file_5_selected.csv\n"
     ]
    }
   ],
   "source": [
    "# List of columns to keep\n",
    "columns_to_keep = [ \n",
    "    'State', 'County', 'total_population', 'Young_Children', 'Children', 'Adolescents', \n",
    "    'Young_Adults', 'Emerging_Workforce', 'Prime_Working_Age', \n",
    "    'Pre_Retirement', 'Seniors', 'Diversity_Index',  \n",
    "    'DP05_0076E', 'DP05_0081E', 'Hispanic_percentage', 'Non_Hispanic_percentage'\n",
    "]\n",
    "\n",
    "# Dictionary to map full state names to 2-letter codes\n",
    "state_abbr = {\n",
    "    'Alabama': 'AL', 'Alaska': 'AK', 'Arizona': 'AZ', 'Arkansas': 'AR',\n",
    "    'California': 'CA', 'Colorado': 'CO', 'Connecticut': 'CT', 'Delaware': 'DE',\n",
    "    'Florida': 'FL', 'Georgia': 'GA', 'Hawaii': 'HI', 'Idaho': 'ID',\n",
    "    'Illinois': 'IL', 'Indiana': 'IN', 'Iowa': 'IA', 'Kansas': 'KS',\n",
    "    'Kentucky': 'KY', 'Louisiana': 'LA', 'Maine': 'ME', 'Maryland': 'MD',\n",
    "    'Massachusetts': 'MA', 'Michigan': 'MI', 'Minnesota': 'MN', 'Mississippi': 'MS',\n",
    "    'Missouri': 'MO', 'Montana': 'MT', 'Nebraska': 'NE', 'Nevada': 'NV',\n",
    "    'New Hampshire': 'NH', 'New Jersey': 'NJ', 'New Mexico': 'NM', 'New York': 'NY',\n",
    "    'North Carolina': 'NC', 'North Dakota': 'ND', 'Ohio': 'OH', 'Oklahoma': 'OK',\n",
    "    'Oregon': 'OR', 'Pennsylvania': 'PA', 'Rhode Island': 'RI', 'South Carolina': 'SC',\n",
    "    'South Dakota': 'SD', 'Tennessee': 'TN', 'Texas': 'TX', 'Utah': 'UT',\n",
    "    'Vermont': 'VT', 'Virginia': 'VA', 'Washington': 'WA', 'West Virginia': 'WV',\n",
    "    'Wisconsin': 'WI', 'Wyoming': 'WY', 'District Of Columbia': 'DC'\n",
    "}\n",
    "\n",
    "# Clean state names and apply 2-letter abbreviation\n",
    "file_5_selected['State'] = file_5_selected['State'].astype(str).str.strip().str.title()\n",
    "file_5_selected['State_Abbr'] = file_5_selected['State'].map(state_abbr)\n",
    "\n",
    "# Select only the necessary columns\n",
    "file_5_selected = file_5_selected[columns_to_keep + ['State_Abbr']]\n",
    "\n",
    "# Rename columns for readability\n",
    "new_column_names = {\n",
    "    'Young_Children': 'Young Children (04 years)',\n",
    "    'Children': 'Children (514 years)',\n",
    "    'Adolescents': 'Adolescents (1519 years)',\n",
    "    'Young_Adults': 'Young Adults (2024 years)',\n",
    "    'Emerging_Workforce': 'Emerging Workforce (2534 years)',\n",
    "    'Prime_Working_Age': 'Prime Working Age (3554 years)',\n",
    "    'Pre_Retirement': 'Pre-Retirement (5564 years)',\n",
    "    'Seniors': 'Seniors (65+ years)',\n",
    "    'Diversity_Index': 'Diversity Index',\n",
    "    'total_population': 'Total Population',\n",
    "    'Hispanic_percentage': 'Hispanic or Latino Percentage',\n",
    "    'Non_Hispanic_percentage': 'Non-Hispanic or Latino Percentage',\n",
    "    'DP05_0076E': 'Hispanic or Latino Population',\n",
    "    'DP05_0081E': 'Non-Hispanic or Latino Population'\n",
    "}\n",
    "\n",
    "file_5_selected = file_5_selected.rename(columns=new_column_names)\n",
    "\n",
    "# Drop row 0 (if needed)\n",
    "file_5_selected = file_5_selected.drop(index=0)\n",
    "\n",
    "# Save to CSV\n",
    "file_5_selected.to_csv(f\"{output_path}/file_5_selected.csv\", index=False)\n",
    "print(\" File saved successfully at:\", f\"{output_path}/file_5_selected.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a496aec-ff91-4260-8048-455d7fc651ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by county (and state, if available) and calculate 5-year average\n",
    "county_avg_fmr = all_data.groupby(['county', 'state'])['fmr_1'].mean().reset_index()\n",
    "\n",
    "# Rename column for clarity\n",
    "county_avg_fmr.rename(columns={'fmr_1': 'fmr_1_5yr_avg'}, inplace=True)\n",
    "\n",
    "# Sort by highest average\n",
    "county_avg_fmr = county_avg_fmr.sort_values(by='fmr_1_5yr_avg', ascending=False)\n",
    "\n",
    "# View the result\n",
    "print(county_avg_fmr.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af19b01-5636-4cb8-819e-b685809d090f",
   "metadata": {},
   "outputs": [],
   "source": [
    "county_avg_fmr.to_excel(\"county_fmr_1_5yr_average.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be6d879-8941-41e7-a375-40815b1f06e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by county and state, calculate average fmr_1 over 5 years\n",
    "county_avg_fmr = all_data.groupby(['county', 'state'])['fmr_1'].mean().reset_index()\n",
    "\n",
    "# Rename for clarity\n",
    "county_avg_fmr.rename(columns={'fmr_1': 'fmr_1_5yr_avg'}, inplace=True)\n",
    "\n",
    "# Sort by highest average rent\n",
    "county_avg_fmr = county_avg_fmr.sort_values(by='fmr_1_5yr_avg', ascending=False)\n",
    "\n",
    "# Preview top 20\n",
    "print(county_avg_fmr.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c2ead8-4670-4b97-ae3d-9bb6888d3a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fips_lookup = pd.read_csv(\"https://raw.githubusercontent.com/kjhealy/fips-codes/master/state_and_county_fips_master.csv\")\n",
    "print(fips_lookup.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf810df2-c58d-4f23-ad93-31e36b2d764a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fips_lookup.columns.tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988e20fc-99a4-4ff6-a656-d0351b686a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your fips_lookup already has these columns: ['fips', 'name', 'state']\n",
    "\n",
    "# Step 1: Ensure FIPS codes are zero-padded strings\n",
    "fips_lookup['fips'] = fips_lookup['fips'].astype(str).str.zfill(5)\n",
    "\n",
    "# Step 2: Extract county and state names from 'name' column\n",
    "fips_lookup[['county_name', 'state_name']] = fips_lookup['name'].str.extract(r'^(.*?),\\s*(.*)$')\n",
    "\n",
    "# Step 3: Prepare your main DataFrame with matching FIPS code\n",
    "county_avg_fmr['fips'] = (\n",
    "    county_avg_fmr['state'].astype(int).astype(str).str.zfill(2) +\n",
    "    county_avg_fmr['county'].astype(int).astype(str).str.zfill(3)\n",
    ")\n",
    "\n",
    "# Step 4: Merge on 'fips'\n",
    "county_avg_fmr_named = county_avg_fmr.merge(\n",
    "    fips_lookup[['fips', 'county_name', 'state_name']],\n",
    "    on='fips',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Step 5: View result\n",
    "print(county_avg_fmr_named[['fips', 'state_name', 'county_name', 'fmr_1_5yr_avg']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7281ddbe-580c-4be5-b15f-8aa58c736cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fips_lookup['fips'].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa531c6-e018-4541-b17e-948d81213dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(county_avg_fmr['fips'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbcbe03-28e3-43da-b54d-86621d5b85cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure both FIPS columns are strings and exactly 5 characters\n",
    "fips_lookup['fips'] = fips_lookup['fips'].astype(str).str.zfill(5)\n",
    "county_avg_fmr['fips'] = county_avg_fmr['fips'].astype(str).str.zfill(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb188cfa-c62f-4f05-a0d8-86e648728724",
   "metadata": {},
   "outputs": [],
   "source": [
    "county_avg_fmr_named = county_avg_fmr.merge(\n",
    "    fips_lookup[['fips', 'name', 'state']],\n",
    "    on='fips',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Split full name into county and state (if needed)\n",
    "county_avg_fmr_named[['county_name', 'state_name']] = county_avg_fmr_named['name'].str.extract(r'^(.*?),\\s*(.*)$')\n",
    "\n",
    "# Final check\n",
    "print(county_avg_fmr_named[['fips', 'state_name', 'county_name', 'fmr_1_5yr_avg']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7924e225-c890-46f2-9461-8b285688e578",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fips_lookup[fips_lookup['fips'] == '06075'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2571ea2e-b294-4059-a7eb-f92768498860",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install us\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c9c2bc-4777-464b-b80d-509f14048276",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install us\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8088d1a0-11ec-4c40-8e6e-113a29414f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_abbr_to_name = {\n",
    "    'AL': 'Alabama', 'AK': 'Alaska', 'AZ': 'Arizona', 'AR': 'Arkansas',\n",
    "    'CA': 'California', 'CO': 'Colorado', 'CT': 'Connecticut', 'DE': 'Delaware',\n",
    "    'FL': 'Florida', 'GA': 'Georgia', 'HI': 'Hawaii', 'ID': 'Idaho',\n",
    "    'IL': 'Illinois', 'IN': 'Indiana', 'IA': 'Iowa', 'KS': 'Kansas',\n",
    "    'KY': 'Kentucky', 'LA': 'Louisiana', 'ME': 'Maine', 'MD': 'Maryland',\n",
    "    'MA': 'Massachusetts', 'MI': 'Michigan', 'MN': 'Minnesota', 'MS': 'Mississippi',\n",
    "    'MO': 'Missouri', 'MT': 'Montana', 'NE': 'Nebraska', 'NV': 'Nevada',\n",
    "    'NH': 'New Hampshire', 'NJ': 'New Jersey', 'NM': 'New Mexico',\n",
    "    'NY': 'New York', 'NC': 'North Carolina', 'ND': 'North Dakota',\n",
    "    'OH': 'Ohio', 'OK': 'Oklahoma', 'OR': 'Oregon', 'PA': 'Pennsylvania',\n",
    "    'RI': 'Rhode Island', 'SC': 'South Carolina', 'SD': 'South Dakota',\n",
    "    'TN': 'Tennessee', 'TX': 'Texas', 'UT': 'Utah', 'VT': 'Vermont',\n",
    "    'VA': 'Virginia', 'WA': 'Washington', 'WV': 'West Virginia',\n",
    "    'WI': 'Wisconsin', 'WY': 'Wyoming', 'DC': 'District of Columbia'\n",
    "}\n",
    "\n",
    "fips_lookup['state_name'] = fips_lookup['state'].map(state_abbr_to_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef7a3ea-73d9-46ff-b478-8ff28ad62113",
   "metadata": {},
   "outputs": [],
   "source": [
    "county_avg_fmr_named = county_avg_fmr.merge(\n",
    "    fips_lookup[['fips', 'state_name', 'county_name']],\n",
    "    on='fips',\n",
    "    how='left'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148a345c-fe3e-48ae-b053-67288feebf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(county_avg_fmr_named[['fips', 'state_name', 'county_name', 'fmr_1_5yr_avg']].head(100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ed3c1f-f208-48a7-be40-d7cc4be6e69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(county_avg_fmr_named[['fips', 'state_name', 'county_name', 'fmr_1_5yr_avg']].tail(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea63573-e26b-40d7-a678-fc6fd515d2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "county_avg_fmr_named.to_excel(\"fmr_1_5yr_by_county.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997a7cf4-ba19-4688-bac3-75d9090c2fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# General Setup\n",
    "# ==========================================================\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "#  Set input/output paths\n",
    "input_path = \"/Users/emilsafarov/Library/CloudStorage/OneDrive-Personal/CF/A6/1_sourceing_open_data/US project/Data/Input data/Processed data\"\n",
    "output_path = \"/Users/emilsafarov/Library/CloudStorage/OneDrive-Personal/CF/A6/1_sourceing_open_data/US project/Data/Output data\"\n",
    "\n",
    "#  List all CSV files in the input directory\n",
    "data_files = os.listdir(input_path)\n",
    "\n",
    "#  Get filename for a specific year, with confirmation\n",
    "def get_file_path(year):\n",
    "    matches = [f for f in data_files if f.endswith(f\"analytic_data{year}.csv\")]\n",
    "    if not matches:\n",
    "        raise FileNotFoundError(f\" No file found for year {year}\")\n",
    "    print(f\" Found file for {year}: {matches[0]}\")\n",
    "    return matches[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c33ce42-5838-45ba-ad88-32499eb54638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# PART 1: Process \"Access to Exercise Opportunities\"\n",
    "# ==========================================================\n",
    "\n",
    "#  Load and clean a single year's exercise access data\n",
    "def load_exercise_access_column(filename, year):\n",
    "    df = pd.read_csv(os.path.join(input_path, filename))\n",
    "    df.columns = df.columns.str.strip()  # Remove extra spaces from column names\n",
    "\n",
    "    # Define acceptable column names across years\n",
    "    possible_cols = [\n",
    "        \"Access to exercise opportunities raw value\",\n",
    "        \"Access to Exercise Opportunities raw value\"\n",
    "    ]\n",
    "    value_col = next((col for col in possible_cols if col in df.columns), None)\n",
    "\n",
    "    # Create column if not found\n",
    "    new_col = f'access_exercise_{year}'\n",
    "    if value_col is None:\n",
    "        print(f\"  Column not found in {filename}. Filling {new_col} with NA.\")\n",
    "        df[new_col] = pd.NA\n",
    "    else:\n",
    "        df = df.rename(columns={value_col: new_col})\n",
    "\n",
    "    # Standardize ID columns\n",
    "    df = df.rename(columns={\n",
    "        '5-digit FIPS Code': 'FIPS',\n",
    "        'State Abbreviation': 'State',\n",
    "        'Name': 'County'\n",
    "    })\n",
    "\n",
    "    return df[['FIPS', 'State', 'County', new_col]]\n",
    "\n",
    "#  Load and collect all 5 years into a list\n",
    "exercise_dfs = []\n",
    "for year in range(2020, 2025):\n",
    "    file_path = get_file_path(year)\n",
    "    df = load_exercise_access_column(file_path, year)\n",
    "    exercise_dfs.append(df)\n",
    "\n",
    "#  Merge yearly data side-by-side\n",
    "exercise_access = exercise_dfs[0]\n",
    "for df in exercise_dfs[1:]:\n",
    "    exercise_access = pd.merge(exercise_access, df, on=[\"FIPS\", \"State\", \"County\"], how=\"outer\")\n",
    "\n",
    "#  Calculate the 5-year average for exercise access\n",
    "exercise_cols = [f'access_exercise_{y}' for y in range(2020, 2025)]\n",
    "exercise_access[exercise_cols] = exercise_access[exercise_cols].apply(pd.to_numeric, errors='coerce')\n",
    "exercise_access['access_exercise_mean'] = exercise_access[exercise_cols].mean(axis=1, skipna=True)\n",
    "\n",
    "#  Preview the processed DataFrame\n",
    "exercise_access.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3558f8ea-7c34-49b7-85ed-07ac546b73f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_report = pd.DataFrame({\n",
    "    \"Missing Count\": exercise_access.isna().sum(),\n",
    "    \"Missing %\": (exercise_access.isna().sum() / len(exercise_access) * 100).round(2)\n",
    "})\n",
    "missing_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372b8e4e-af3a-4790-87e2-4488821ca1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the missing values for some columns are under 5 percent, I will impute with the state average for the relevant counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3296a552-5425-4a81-adc9-a8aeab46f398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All missing yearly values (20202024) are filled using that state's average exercise access score that county belong\n",
    "\n",
    "# Step 1: Define the year columns to impute\n",
    "year_cols = [f'access_exercise_{y}' for y in range(2020, 2025)]\n",
    "\n",
    "# Step 2: Loop through each state and impute missing values\n",
    "states = exercise_access['State'].unique()\n",
    "\n",
    "for state in states:\n",
    "    # Get the state's mean 5-year average (excluding NaNs)\n",
    "    state_mean = exercise_access.loc[\n",
    "        exercise_access['State'] == state, 'access_exercise_mean'\n",
    "    ].mean()\n",
    "    \n",
    "    # Loop through each year column and fill missing values with that state mean\n",
    "    for col in year_cols:\n",
    "        exercise_access.loc[\n",
    "            (exercise_access['State'] == state) & (exercise_access[col].isna()),\n",
    "            col\n",
    "        ] = state_mean\n",
    "\n",
    "# Step 3: Recalculate the 5-year mean for all rows after imputation\n",
    "exercise_access[year_cols] = exercise_access[year_cols].apply(pd.to_numeric, errors='coerce')\n",
    "exercise_access['access_exercise_mean'] = exercise_access[year_cols].mean(axis=1, skipna=True)\n",
    "\n",
    "print(\" All missing values have been imputed using state-wise means.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358f1d4d-b043-46f2-8710-7e07ee240156",
   "metadata": {},
   "outputs": [],
   "source": [
    "exercise_access.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27a8d3a-7a92-4435-b059-644e9dcf7703",
   "metadata": {},
   "source": [
    " General Interpretation: Access to Exercise Opportunities (20202024)\n",
    "This dataset shows the proportion of each countys population with adequate access to locations for physical activity (e.g., parks, gyms, trails) over a 5-year period.\n",
    "\n",
    "Values range from 0 (no access) to 1 (full access), with access_exercise_mean reflecting the 5-year average.\n",
    "\n",
    " What it tells us:\n",
    "Higher values (e.g., 0.70+) = broad community access to exercise spaces \n",
    "Lower values (e.g., < 0.10) = limited access, likely rural or underserved areas \n",
    "Important for understanding health equity and targeting community health investments.\n",
    " Data Note:\n",
    "Some counties had missing data, which was filled using their states average score to enable fair comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479ed663-bf35-4a49-aa94-46c52680c298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# PART 2: Process \"Air Pollution  Particulate Matter\"\n",
    "# ==========================================================\n",
    "\n",
    "#  Load and clean a single year's air pollution data\n",
    "def load_air_pollution_column(filename, year):\n",
    "    df = pd.read_csv(os.path.join(input_path, filename))\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    # Handle name variations for the air pollution column\n",
    "    possible_cols = [\n",
    "        \"Air pollution - particulate matter raw value\",\n",
    "        \"Air Pollution - Particulate Matter raw value\"\n",
    "    ]\n",
    "    value_col = next((col for col in possible_cols if col in df.columns), None)\n",
    "\n",
    "    new_col = f'air_pollution_{year}'\n",
    "    if value_col is None:\n",
    "        print(f\"  Column not found in {filename}. Filling {new_col} with NA.\")\n",
    "        df[new_col] = pd.NA\n",
    "    else:\n",
    "        df = df.rename(columns={value_col: new_col})\n",
    "\n",
    "    # Standardize ID columns\n",
    "    df = df.rename(columns={\n",
    "        '5-digit FIPS Code': 'FIPS',\n",
    "        'State Abbreviation': 'State',\n",
    "        'Name': 'County'\n",
    "    })\n",
    "\n",
    "    return df[['FIPS', 'State', 'County', new_col]]\n",
    "\n",
    "#  Load and collect all 5 years into a list\n",
    "air_dfs = []\n",
    "for year in range(2020, 2025):\n",
    "    file_path = get_file_path(year)\n",
    "    df = load_air_pollution_column(file_path, year)\n",
    "    air_dfs.append(df)\n",
    "\n",
    "#  Merge yearly data side-by-side\n",
    "air_pollution = air_dfs[0]\n",
    "for df in air_dfs[1:]:\n",
    "    air_pollution = pd.merge(air_pollution, df, on=[\"FIPS\", \"State\", \"County\"], how=\"outer\")\n",
    "\n",
    "#  Calculate the 5-year average for air pollution\n",
    "air_cols = [f'air_pollution_{y}' for y in range(2020, 2025)]\n",
    "air_pollution[air_cols] = air_pollution[air_cols].apply(pd.to_numeric, errors='coerce')\n",
    "air_pollution['air_pollution_mean'] = air_pollution[air_cols].mean(axis=1, skipna=True)\n",
    "\n",
    "#  Preview the processed DataFrame\n",
    "air_pollution.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42715c5a-fe24-4580-bb9d-924a5687fb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_report = pd.DataFrame({\n",
    "    \"Missing Count\": air_pollution.isna().sum(),\n",
    "    \"Missing %\": (air_pollution.isna().sum() / len(air_pollution) * 100).round(2)\n",
    "})\n",
    "missing_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7defef8-a78a-43a7-a05a-0b2faf5718ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# Impute Missing Values: Air Pollution (20202024)\n",
    "# ==========================================================\n",
    "\n",
    "# Step 1: Define the year columns to impute\n",
    "air_cols = [f'air_pollution_{y}' for y in range(2020, 2025)]\n",
    "\n",
    "# Step 2: Loop through each state and impute missing values\n",
    "states = air_pollution['State'].unique()\n",
    "\n",
    "for state in states:\n",
    "    # Get the state's mean 5-year average (excluding NaNs)\n",
    "    state_mean = air_pollution.loc[\n",
    "        air_pollution['State'] == state, 'air_pollution_mean'\n",
    "    ].mean()\n",
    "    \n",
    "    # Loop through each year column and fill missing values with that state mean\n",
    "    for col in air_cols:\n",
    "        air_pollution.loc[\n",
    "            (air_pollution['State'] == state) & (air_pollution[col].isna()),\n",
    "            col\n",
    "        ] = state_mean\n",
    "\n",
    "# Step 3: Recalculate the 5-year mean for all rows after imputation\n",
    "air_pollution[air_cols] = air_pollution[air_cols].apply(pd.to_numeric, errors='coerce')\n",
    "air_pollution['air_pollution_mean'] = air_pollution[air_cols].mean(axis=1, skipna=True)\n",
    "\n",
    "print(\" All missing air pollution values have been imputed using state-wise means.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17805f75-b0e2-445a-a1a8-5a2b9bd6469f",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_pollution.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe63990c-6e7e-447a-a414-5a5d528db20e",
   "metadata": {},
   "source": [
    " General Interpretation: Air Pollution (PM2.5), 20202024\n",
    "This dataset shows the annual average concentration of fine particulate matter (PM2.5, g/m) in each U.S. county over 5 years. The air_pollution_mean reflects each countys 5-year average exposure.\n",
    "\n",
    " What it tells us:\n",
    "Lower values (79) = cleaner air\n",
    "Higher values (10+) = more pollution, greater health risk\n",
    "Helps identify environmental health disparities and areas needing air quality improvement.\n",
    " Standards:\n",
    "EPA limit: 12 g/m (annual average)\n",
    "WHO guideline: 5 g/m (2021 update)\n",
    "Most U.S. counties stay under EPAs limit but exceed WHOs target.\n",
    " Data Note:\n",
    "Missing values (for some counties/years) were imputed using state-level means for consistent comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec23137e-a10d-4712-8b47-9c10e3a921d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# PART 3: Drinking Water Violations\n",
    "# ==========================================================\n",
    "\n",
    "#  Load and clean a single year's drinking water violation data\n",
    "def load_drinking_water_column(filename, year):\n",
    "    df = pd.read_csv(os.path.join(input_path, filename))\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    possible_cols = [\n",
    "        \"Drinking water violations raw value\",\n",
    "        \"Drinking Water Violations raw value\"\n",
    "    ]\n",
    "    value_col = next((col for col in possible_cols if col in df.columns), None)\n",
    "\n",
    "    new_col = f'drinking_water_{year}'\n",
    "    if value_col is None:\n",
    "        print(f\"  Column not found in {filename}. Filling {new_col} with NA.\")\n",
    "        df[new_col] = pd.NA\n",
    "    else:\n",
    "        df = df.rename(columns={value_col: new_col})\n",
    "\n",
    "    df = df.rename(columns={\n",
    "        '5-digit FIPS Code': 'FIPS',\n",
    "        'State Abbreviation': 'State',\n",
    "        'Name': 'County'\n",
    "    })\n",
    "\n",
    "    return df[['FIPS', 'State', 'County', new_col]]\n",
    "\n",
    "#  Load all 5 years\n",
    "water_dfs = []\n",
    "for year in range(2020, 2025):\n",
    "    file_path = get_file_path(year)\n",
    "    df = load_drinking_water_column(file_path, year)\n",
    "    water_dfs.append(df)\n",
    "\n",
    "#  Merge yearly data\n",
    "drinking_water = water_dfs[0]\n",
    "for df in water_dfs[1:]:\n",
    "    drinking_water = pd.merge(drinking_water, df, on=[\"FIPS\", \"State\", \"County\"], how=\"outer\")\n",
    "\n",
    "#  Calculate 5-year average\n",
    "water_cols = [f'drinking_water_{y}' for y in range(2020, 2025)]\n",
    "drinking_water[water_cols] = drinking_water[water_cols].apply(pd.to_numeric, errors='coerce')\n",
    "drinking_water['drinking_water_mean'] = drinking_water[water_cols].mean(axis=1, skipna=True)\n",
    "\n",
    "#  Impute missing values by state-wise mean\n",
    "states = drinking_water['State'].unique()\n",
    "for state in states:\n",
    "    state_mean = drinking_water.loc[drinking_water['State'] == state, 'drinking_water_mean'].mean()\n",
    "    for col in water_cols:\n",
    "        drinking_water.loc[\n",
    "            (drinking_water['State'] == state) & (drinking_water[col].isna()),\n",
    "            col\n",
    "        ] = state_mean\n",
    "\n",
    "#  Recalculate mean after imputation\n",
    "drinking_water[water_cols] = drinking_water[water_cols].apply(pd.to_numeric, errors='coerce')\n",
    "drinking_water['drinking_water_mean'] = drinking_water[water_cols].mean(axis=1, skipna=True)\n",
    "\n",
    "#  Final missing check\n",
    "missing_report = pd.DataFrame({\n",
    "    \"Missing Count\": drinking_water.isna().sum(),\n",
    "    \"Missing %\": (drinking_water.isna().sum() / len(drinking_water) * 100).round(2)\n",
    "})\n",
    "print(\" Final Missing Value Report: Drinking Water\")\n",
    "print(missing_report)\n",
    "\n",
    "#  Preview result\n",
    "drinking_water.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dbc27e-3938-4948-9961-171c4efefd57",
   "metadata": {},
   "source": [
    " General Interpretation: Drinking Water Violations Data (20202024)\n",
    "This dataset tracks how frequently each U.S. county violated drinking water safety standards over 5 years.\n",
    "Each year is represented by a value from 0 (no violations) to 1 (violations throughout the year). The column drinking_water_mean summarizes a countys 5-year average violation rate.\n",
    "\n",
    "Counties with values close to 0 consistently provided safe drinking water, while higher averages (e.g., 0.6) signal frequent or recurring water quality issues. This helps identify areas where public health infrastructure may require attention.\n",
    "\n",
    "Some counties have not reported data for specific years. In those cases, missing values were imputed using the state-level average, allowing for fair comparison across all counties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540568f2-9332-44e3-99a3-ebb607725b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# PART 4: Violent Crime (Full Script with Detailed Logging)\n",
    "# ==========================================================\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "#  Load and clean a single year's violent crime data\n",
    "def load_violent_crime_column(filename, year):\n",
    "    df = pd.read_csv(os.path.join(input_path, filename))\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    possible_cols = [\n",
    "        \"Violent crime raw value\",\n",
    "        \"Violent Crime raw value\"\n",
    "    ]\n",
    "    value_col = next((col for col in possible_cols if col in df.columns), None)\n",
    "\n",
    "    new_col = f'violent_crime_{year}'\n",
    "    if value_col is None:\n",
    "        print(f\"  Column not found in {filename}. Filling {new_col} with NA.\")\n",
    "        df[new_col] = pd.NA\n",
    "    else:\n",
    "        df = df.rename(columns={value_col: new_col})\n",
    "\n",
    "    df = df.rename(columns={\n",
    "        '5-digit FIPS Code': 'FIPS',\n",
    "        'State Abbreviation': 'State',\n",
    "        'Name': 'County'\n",
    "    })\n",
    "\n",
    "    return df[['FIPS', 'State', 'County', new_col]]\n",
    "\n",
    "#  Load all 5 years\n",
    "crime_dfs = []\n",
    "for year in range(2020, 2025):\n",
    "    file_path = get_file_path(year)\n",
    "    df = load_violent_crime_column(file_path, year)\n",
    "    crime_dfs.append(df)\n",
    "\n",
    "#  Merge yearly data\n",
    "violent_crime = crime_dfs[0]\n",
    "for df in crime_dfs[1:]:\n",
    "    violent_crime = pd.merge(violent_crime, df, on=[\"FIPS\", \"State\", \"County\"], how=\"outer\")\n",
    "\n",
    "#  Calculate 5-year average BEFORE imputation\n",
    "crime_cols = [f'violent_crime_{y}' for y in range(2020, 2025)]\n",
    "violent_crime[crime_cols] = violent_crime[crime_cols].apply(pd.to_numeric, errors='coerce')\n",
    "violent_crime['violent_crime_mean'] = violent_crime[crime_cols].mean(axis=1, skipna=True)\n",
    "\n",
    "#  Missing check BEFORE imputation\n",
    "missing_report_before = pd.DataFrame({\n",
    "    \"Missing Count\": violent_crime.isna().sum(),\n",
    "    \"Missing %\": (violent_crime.isna().sum() / len(violent_crime) * 100).round(2)\n",
    "})\n",
    "print(\" Missing Value Report BEFORE Imputation: Violent Crime\")\n",
    "print(missing_report_before)\n",
    "\n",
    "#  Print state-wise means used for imputation\n",
    "print(\"\\n State-Level Means Used for Imputing Violent Crime:\")\n",
    "state_means = {}\n",
    "\n",
    "states = violent_crime['State'].unique()\n",
    "for state in states:\n",
    "    state_mean = violent_crime.loc[violent_crime['State'] == state, 'violent_crime_mean'].mean()\n",
    "    state_means[state] = state_mean\n",
    "    # Impute missing values for this state\n",
    "    for col in crime_cols:\n",
    "        violent_crime.loc[\n",
    "            (violent_crime['State'] == state) & (violent_crime[col].isna()),\n",
    "            col\n",
    "        ] = state_mean\n",
    "\n",
    "# Show as DataFrame\n",
    "state_means_df = pd.DataFrame.from_dict(state_means, orient='index', columns=['State Mean (Violent Crime)'])\n",
    "state_means_df = state_means_df.sort_values(by='State Mean (Violent Crime)', ascending=False)\n",
    "print(state_means_df)\n",
    "\n",
    "#  Recalculate mean AFTER imputation\n",
    "violent_crime[crime_cols] = violent_crime[crime_cols].apply(pd.to_numeric, errors='coerce')\n",
    "violent_crime['violent_crime_mean'] = violent_crime[crime_cols].mean(axis=1, skipna=True)\n",
    "\n",
    "#  Final missing check AFTER imputation\n",
    "missing_report_after = pd.DataFrame({\n",
    "    \"Missing Count\": violent_crime.isna().sum(),\n",
    "    \"Missing %\": (violent_crime.isna().sum() / len(violent_crime) * 100).round(2)\n",
    "})\n",
    "print(\"\\n Final Missing Value Report AFTER Imputation: Violent Crime\")\n",
    "print(missing_report_after)\n",
    "\n",
    "#  Compare before vs after side-by-side\n",
    "missing_compare = pd.concat(\n",
    "    [missing_report_before.rename(columns=lambda c: f\"Before {c}\"),\n",
    "     missing_report_after.rename(columns=lambda c: f\"After {c}\")],\n",
    "    axis=1\n",
    ")\n",
    "print(\"\\n Missing Value Comparison: Violent Crime (Before vs After)\")\n",
    "print(missing_compare)\n",
    "\n",
    "#  Identify row(s) still missing after imputation\n",
    "still_missing = violent_crime[violent_crime.isna().any(axis=1)]\n",
    "print(\"\\n Row(s) still missing after imputation:\")\n",
    "print(still_missing[['FIPS', 'State', 'County'] + crime_cols + ['violent_crime_mean']])\n",
    "\n",
    "#  Optional: Impute final row(s) with national mean\n",
    "if not still_missing.empty:\n",
    "    national_mean = violent_crime['violent_crime_mean'].mean()\n",
    "    violent_crime.fillna(national_mean, inplace=True)\n",
    "    print(f\"\\n Filled final missing values with national mean: {round(national_mean, 4)}\")\n",
    "\n",
    "#  Preview final cleaned data\n",
    "print(\"\\n Preview of final violent_crime data:\")\n",
    "print(violent_crime.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac78f9e-61f1-4b7a-8710-142114828f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# File Check: Validate all expected files are present\n",
    "# ==========================================================\n",
    "\n",
    "# Define the years to check\n",
    "years_to_check = range(2020, 2025)\n",
    "\n",
    "# Loop through each year and confirm file exists\n",
    "print(\" Checking required files...\")\n",
    "for year in years_to_check:\n",
    "    try:\n",
    "        file = get_file_path(year)\n",
    "    except FileNotFoundError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059fa01b-7344-4626-8303-ed1fe7c51e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# Preview: Violent Crime Raw Value (Year: 2024)\n",
    "# ==========================================================\n",
    "\n",
    "# Load 2024 data file\n",
    "file_2024 = get_file_path(2024)\n",
    "df_2024 = pd.read_csv(os.path.join(input_path, file_2024))\n",
    "df_2024.columns = df_2024.columns.str.strip()\n",
    "\n",
    "# Try to find the correct column (handling name inconsistencies)\n",
    "possible_cols = [\n",
    "    \"Violent crime raw value\",\n",
    "    \"Violent Crime raw value\"\n",
    "]\n",
    "\n",
    "crime_col = next((col for col in possible_cols if col in df_2024.columns), None)\n",
    "\n",
    "if crime_col:\n",
    "    # Standardize and preview\n",
    "    df_2024 = df_2024.rename(columns={crime_col: \"violent_crime_2024\"})\n",
    "    \n",
    "    # Clean up key columns\n",
    "    df_2024 = df_2024.rename(columns={\n",
    "        '5-digit FIPS Code': 'FIPS',\n",
    "        'State Abbreviation': 'State',\n",
    "        'Name': 'County'\n",
    "    })\n",
    "\n",
    "    print(\" Preview: Violent Crime Data (2024)\")\n",
    "    display(df_2024[['FIPS', 'State', 'County', 'violent_crime_2024']].head())\n",
    "else:\n",
    "    print(\" Violent crime column not found in 2024 file.\")\n",
    "``\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fbb410-e141-4e6e-a08e-7ff9b78e3881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# Preview: Violent Crime Raw Value (2024)\n",
    "# ==========================================================\n",
    "\n",
    "# Load the 2024 file\n",
    "file_2024 = get_file_path(2024)\n",
    "df_2024 = pd.read_csv(os.path.join(input_path, file_2024))\n",
    "df_2024.columns = df_2024.columns.str.strip()\n",
    "\n",
    "# Extract the column: \"Violent crime raw value\"\n",
    "crime_col = \"Violent crime raw value\"\n",
    "\n",
    "if crime_col in df_2024.columns:\n",
    "    # Rename and clean for preview\n",
    "    df_2024 = df_2024.rename(columns={\n",
    "        crime_col: \"violent_crime_2024\",\n",
    "        '5-digit FIPS Code': 'FIPS',\n",
    "        'State Abbreviation': 'State',\n",
    "        'Name': 'County'\n",
    "    })\n",
    "\n",
    "    # Preview selected columns\n",
    "    print(\" Preview: Violent Crime Raw Value (2024)\")\n",
    "    display(df_2024[['FIPS', 'State', 'County', 'violent_crime_2024']].head())\n",
    "else:\n",
    "    print(\" 'Violent crime raw value' column not found in 2024 file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9c37ee-42e2-499a-a595-cb7ffcb026d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check all column names in the 2024 file\n",
    "print(\" Column names in 2024 file:\")\n",
    "for col in df_2024.columns:\n",
    "    print(\"-\", col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ada0fee-af1e-4625-8fd9-caaf8d1fb9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# Check Violent Crime Column in 2024 File\n",
    "# ==========================================================\n",
    "\n",
    "# Load the 2024 file\n",
    "file_2024 = get_file_path(2024)\n",
    "df_2024 = pd.read_csv(os.path.join(input_path, file_2024))\n",
    "df_2024.columns = df_2024.columns.str.strip()\n",
    "\n",
    "# Step 1: Print all column names to find the real one\n",
    "print(\" All column names in 2024 file:\")\n",
    "for col in df_2024.columns:\n",
    "    print(\"-\", col)\n",
    "\n",
    "# Step 2: Try to auto-detect a close match (just in case)\n",
    "import difflib\n",
    "match = difflib.get_close_matches(\"Violent crime raw value\", df_2024.columns, n=1)\n",
    "\n",
    "if match:\n",
    "    col_name = match[0]\n",
    "    print(f\"\\n Closest match found: '{col_name}'\")\n",
    "\n",
    "    # Step 3: Preview first 5 rows from that column\n",
    "    print(\"\\n First 5 values from the violent crime column:\")\n",
    "    print(df_2024[[col_name]].head())\n",
    "else:\n",
    "    print(\"\\n No close match found for 'Violent crime raw value'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db2cb3a-bdad-48a5-9742-4c206208841c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
